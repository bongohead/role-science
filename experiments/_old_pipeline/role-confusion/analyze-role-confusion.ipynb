{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beade33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test role confusion with hidden states\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cupy\n",
    "import cuml\n",
    "\n",
    "import importlib\n",
    "import gc\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from utils.memory import check_memory, clear_all_cuda_memory\n",
    "from utils.gptoss import run_gptoss_return_topk\n",
    "from utils.harmony import render_prompt\n",
    "\n",
    "main_device = 'cuda:0'\n",
    "seed = 1234\n",
    "\n",
    "clear_all_cuda_memory()\n",
    "check_memory()\n",
    "\n",
    "ws = '/workspace/deliberative-alignment-jailbreaks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26db3f",
   "metadata": {},
   "source": [
    "## Load models & data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75666ea5",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80af64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model_index = 1\n",
    "\n",
    "def get_model(index):\n",
    "    # HF model ID, model prefix, model architecture,  attn implementation, whether to use hf lib implementation\n",
    "    models = {\n",
    "        0: ('openai/gpt-oss-120b', 'gptoss120', 'gptoss', 'kernels-community/vllm-flash-attn3', True), # Will load experts in MXFP4 if triton kernels installed\n",
    "        1: ('openai/gpt-oss-20b', 'gptoss20', 'gptoss', 'kernels-community/vllm-flash-attn3', True)\n",
    "    }\n",
    "    return models[index]\n",
    "\n",
    "def load_model_and_tokenizer(model_id, model_prefix, model_attn, model_use_hf):\n",
    "    \"\"\"\n",
    "    Load the model and tokenizer from HF, or from file if already downloaded.\n",
    "    \"\"\"\n",
    "    cache_dir = '/workspace/hf'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir = cache_dir, add_eos_token = False, add_bos_token = False, padding_side = 'left', trust_remote_code = True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir = cache_dir, dtype = torch.bfloat16, trust_remote_code = not model_use_hf, device_map = 'auto', attn_implementation = model_attn).eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "model_id, model_prefix, model_architecture, model_attn, model_use_hf = get_model(selected_model_index)\n",
    "tokenizer, model = load_model_and_tokenizer(model_id, model_prefix, model_attn, model_use_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11e85b",
   "metadata": {},
   "source": [
    "### Load c4 role activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0533d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load dataset\n",
    "\"\"\"\n",
    "def load_data(folder_path, model_prefix, max_data_files):\n",
    "    \"\"\"\n",
    "    Load data saved by `export-activations.ipynb`\n",
    "    \"\"\"\n",
    "    folders = [f'./{folder_path}/{model_prefix}/{i:02d}' for i in range(max_data_files)]\n",
    "    folders = [f for f in folders if os.path.isdir(f)]\n",
    "\n",
    "    all_pre_mlp_hs = []\n",
    "    sample_df = []\n",
    "    topk_df = []\n",
    "\n",
    "    for f in tqdm(folders):\n",
    "        sample_df.append(pd.read_pickle(f'{f}/samples.pkl'))\n",
    "        topk_df.append(pd.read_pickle(f'{f}/topks.pkl'))\n",
    "        all_pre_mlp_hs.append(torch.load(f'{f}/all-pre-mlp-hidden-states.pt'))\n",
    "\n",
    "    sample_df = pd.concat(sample_df)\n",
    "    topk_df = pd.concat(topk_df)\n",
    "    all_pre_mlp_hs = torch.concat(all_pre_mlp_hs)    \n",
    "\n",
    "    with open(f'./{folder_path}/{model_prefix}/metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    gc.collect()\n",
    "    return sample_df, topk_df, all_pre_mlp_hs, metadata['all_pre_mlp_hidden_states_layers']\n",
    "\n",
    "sample_df_import, topk_df_import, all_pre_mlp_hs_import, act_map = load_data('activations-c4', 'gptoss20', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's clean up the mappings here. We'll get everything to a sample_ix level first. We'll also flag the role wrapper tokens. Drop nothing. \n",
    "\"\"\"\n",
    "input_mappings = pd.read_csv('./activations-c4/gptoss20/input_mappings.csv')\n",
    "display(input_mappings)\n",
    "\n",
    "sample_df_raw =\\\n",
    "    sample_df_import\\\n",
    "    .assign(seq_id = lambda df: df.groupby(['batch_ix', 'sequence_ix']).ngroup())\\\n",
    "    .merge(input_mappings[['prompt_ix', 'question_ix', 'role']], how = 'left', on = ['prompt_ix'])\\\n",
    "    .assign(\n",
    "        l1 = lambda d: d.groupby('prompt_ix')['token'].shift(1),\n",
    "        l2 = lambda d: d.groupby('prompt_ix')['token'].shift(2),\n",
    "        is_role_wrapper = lambda df: np.where(\n",
    "            (df['token'].isin(['<|start|>', '<|channel|>', '<|message|>', '<|end|>', '<|return|>'])) | (df['l1'].isin(['<|start|>', '<|channel|>'])), \n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "    )\\\n",
    "    .drop(columns = ['l1', 'l2'])\\\n",
    "    .reset_index(drop = True)\\\n",
    "    .assign(sample_ix = lambda df: df.groupby(['batch_ix', 'sequence_ix', 'token_ix']).ngroup())\n",
    "\n",
    "c4_topk_df =\\\n",
    "    topk_df_import\\\n",
    "    .merge(sample_df_raw[['sample_ix', 'prompt_ix', 'batch_ix', 'sequence_ix', 'token_ix']], how = 'inner', on = ['sequence_ix', 'token_ix', 'batch_ix'])\\\n",
    "    .drop(columns = ['sequence_ix', 'token_ix', 'batch_ix'])\n",
    "\n",
    "\n",
    "c4_sample_df =\\\n",
    "    sample_df_raw\\\n",
    "    .drop(columns = ['batch_ix', 'sequence_ix'])\n",
    "\n",
    "del sample_df_import, sample_df_raw, topk_df_import\n",
    "\n",
    "gc.collect()\n",
    "display(c4_topk_df)\n",
    "display(c4_sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81cc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert activations to fp16 (for compatibility with cupy later) + layer-wise dict\n",
    "\"\"\"\n",
    "c4_all_pre_mlp_hs = all_pre_mlp_hs_import.to(torch.float16)\n",
    "# compare_bf16_fp16_batched(all_pre_mlp_hs_import, all_pre_mlp_hs)\n",
    "del all_pre_mlp_hs_import\n",
    "c4_all_pre_mlp_hs = {layer_ix: c4_all_pre_mlp_hs[:, save_ix, :] for save_ix, layer_ix in enumerate(act_map)}\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77aa71b",
   "metadata": {},
   "source": [
    "### Load jailbreak dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load dataset\n",
    "\"\"\"\n",
    "sample_df_import, topk_df_import, all_pre_mlp_hs_import, act_map = load_data('activations-redteam', 'gptoss20', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Clean up the mappings and get everything to a sample_ix (token-level). Additionally, map everything to its correct role.\n",
    "Due to the business logic in `export-jailbreak-activations.ipynb`, every sequence should have all components (system/user/component)\n",
    "\"\"\"\n",
    "sample_df_raw =\\\n",
    "    sample_df_import\\\n",
    "    .assign(seq_id = lambda df: df.groupby(['batch_ix', 'sequence_ix']).ngroup())\\\n",
    "    .assign(\n",
    "        l1 = lambda d: d['token'].shift(1),\n",
    "        l2 = lambda d: d['token'].shift(2),\n",
    "        f1 = lambda d: d['token'].shift(-1),\n",
    "        f2 = lambda d: d['token'].shift(-2),\n",
    "        is_role_wrapper = lambda df: np.where(\n",
    "            (df['token'].isin(['<|start|>', '<|channel|>', '<|message|>', '<|end|>', '<|return|>'])) | (df['l1'].isin(['<|start|>', '<|channel|>'])), \n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "    )\\\n",
    "    .assign(role = lambda df: np.select(\n",
    "        [\n",
    "            (df['token'] == 'user') & (df['l1'] == '<|start|>'),\n",
    "            (df['token'] == 'assistant') & (df['l1'] == '<|start|>') & (df['f1'] == '<|channel|>') & (df['f2'] == 'analysis'),\n",
    "            (df['token'] == 'assistant') & (df['l1'] == '<|start|>') & (df['f1'] == '<|channel|>') & (df['f2'] == 'comment'),\n",
    "            (df['token'] == 'assistant') & (df['l1'] == '<|start|>') & (df['f1'] == '<|channel|>') & (df['f2'] == 'final'),\n",
    "            (df['token'] == 'system') & (df['l1'] == '<|start|>'),\n",
    "        ],\n",
    "        [\n",
    "            'user',\n",
    "            'cot',\n",
    "            'cot',\n",
    "            'assistant',\n",
    "            'system'\n",
    "        ],\n",
    "        None\n",
    "    ))\\\n",
    "    .assign(\n",
    "        role = lambda df: np.where(df['is_role_wrapper'] == 0, df['role'].ffill(), None)\n",
    "    )\\\n",
    "    .drop(columns = ['l1', 'l2', 'f1', 'f2', 'is_role_wrapper'])\\\n",
    "    .assign(sample_ix = lambda df: df.groupby(['batch_ix', 'sequence_ix', 'token_ix']).ngroup())\\\n",
    "    .assign(token_in_seq_ix = lambda df: df.groupby(['seq_id']).cumcount())\\\n",
    "    .assign(token_in_roel_ix = lambda df: df.groupby(['seq_id', 'role']).cumcount())\n",
    "\n",
    "\n",
    "redteam_topk_df =\\\n",
    "    topk_df_import\\\n",
    "    .merge(sample_df_raw[['sample_ix', 'prompt_ix', 'batch_ix', 'sequence_ix', 'token_ix']], how = 'inner', on = ['sequence_ix', 'token_ix', 'batch_ix'])\\\n",
    "    .drop(columns = ['sequence_ix', 'token_ix', 'batch_ix'])\n",
    "\n",
    "redteam_sample_df =\\\n",
    "    sample_df_raw\\\n",
    "    .drop(columns = ['batch_ix', 'sequence_ix'])\n",
    "\n",
    "# del sample_df_import, sample_df_raw, topk_df_import\n",
    "\n",
    "gc.collect()\n",
    "display(redteam_topk_df)\n",
    "display(redteam_sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert activations to fp16 (for compatibility with cupy later) + layer-wise dict\n",
    "\"\"\"\n",
    "redteam_all_pre_mlp_hs = all_pre_mlp_hs_import.to(torch.float16)\n",
    "# compare_bf16_fp16_batched(all_pre_mlp_hs_import, all_pre_mlp_hs)\n",
    "del all_pre_mlp_hs_import\n",
    "redteam_all_pre_mlp_hs = {layer_ix: redteam_all_pre_mlp_hs[:, save_ix, :] for save_ix, layer_ix in enumerate(act_map)}\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get sequence level redteam data\n",
    "\"\"\"\n",
    "redteam_seqs_df = pd.read_csv('./redteam-generations.csv')\n",
    "redteam_seqs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31394585",
   "metadata": {},
   "outputs": [],
   "source": [
    "redteam_sample_df.head(1_000).to_csv('tmp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66616eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Split by roles\n",
    "# \"\"\"\n",
    "# role_hs = {}\n",
    "# role_sample_dfs = {}\n",
    "# role_topk_dfs = {}\n",
    "\n",
    "# for role in sample_df['role'].unique().tolist():\n",
    "#     role_sample_dfs[role] = sample_df.pipe(lambda df: df[df['role'] == role]).pipe(lambda df: df[df['is_role_wrapper'] == 0])\n",
    "#     role_topk_dfs[role] = topk_df[topk_df['sample_ix'].isin(role_sample_dfs[role]['sample_ix'].tolist())]\n",
    "\n",
    "#     role_hs[role] = {l: all_pre_mlp_hs[l][role_sample_dfs[role]['sample_ix'].tolist(), :] for l in all_pre_mlp_hs.keys()}\n",
    "#     print(role_hs[role][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc62db",
   "metadata": {},
   "source": [
    "## Role spaces (logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac139eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run logistic regression on c4 to get a model for role predictions\n",
    "\"\"\"\n",
    "def run_lr(x_cp, y_cp):\n",
    "    x_train, x_test, y_train, y_test = cuml.train_test_split(x_cp, y_cp, test_size = 0.2, random_state = 123)\n",
    "    lr_model = cuml.linear_model.LogisticRegression(penalty = 'l2', C = 0.0001, max_iter = 1000, fit_intercept = True)\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    accuracy = lr_model.score(x_test, y_test)\n",
    "    return lr_model, accuracy\n",
    "\n",
    "test_layer = 12\n",
    "label_to_id = {'system': 0, 'user': 1, 'cot': 2, 'assistant': 3}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "valid_sample_ix = c4_sample_df.pipe(lambda df: df[df['is_role_wrapper'] == 0])['sample_ix'].tolist()\n",
    "\n",
    "role_labels = [\n",
    "    label_to_id[role]\n",
    "    for role in c4_sample_df[c4_sample_df['sample_ix'].isin(valid_sample_ix)]['role'].tolist()\n",
    "]\n",
    "\n",
    "role_labels_cp = cupy.asarray(role_labels)\n",
    "x_cp = cupy.asarray(c4_all_pre_mlp_hs[test_layer][valid_sample_ix, :].to(torch.float16).detach().cpu())\n",
    "lr_model, test_acc = run_lr(x_cp, role_labels_cp)\n",
    "\n",
    "print(test_acc)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07198ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Project redteam activations into roles - start with just one sequence\n",
    "\"\"\"\n",
    "# Test sequences - get all variants\n",
    "test_variants = redteam_seqs_df.pipe(lambda df: df[df['harm_index'] == redteam_seqs_df['harm_index'].tolist()[19]])\n",
    "\n",
    "test_variant_results = []\n",
    "for row in test_variants.to_records('dict'):\n",
    "    seq_samples = redteam_sample_df.pipe(lambda df: df[df['seq_id'] == row['redteam_seq_ix']]).pipe(lambda df: df[df['role'].notna()]).reset_index(drop = True)\n",
    "\n",
    "    seq_hs_cp = cupy.asarray(redteam_all_pre_mlp_hs[test_layer][seq_samples['sample_ix'].tolist(), :])\n",
    "\n",
    "    seq_probs = lr_model.predict_proba(seq_hs_cp).round(6)\n",
    "\n",
    "    # Merge seq probs with inputs\n",
    "    plot_df =\\\n",
    "        pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(cupy.asnumpy(seq_probs), columns = ['user', 'assistant', 'cot', 'system']).clip(1e-6),\n",
    "                seq_samples[['token_in_seq_ix', 'token', 'role']]\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "    test_variant_results.append({\n",
    "        'variant': row['redteam_prompt_type'],\n",
    "        'output_class': row['output_class'],\n",
    "        'plot_df': plot_df\n",
    "    })\n",
    "\n",
    "test_variant_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b126cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_role_prob_minimal(\n",
    "    input_df: pd.DataFrame,\n",
    "    *,\n",
    "    title: str = '',\n",
    "    value_col: str = \"cot\", # one of: 'cot','assistant','user','system'\n",
    "    rolling_window: int = 35, # used for line mode only\n",
    "    use_points: bool = False, # True -> markers (raw), False -> line (smoothed)\n",
    "    export_path: str = None # e.g. \"figure.svg\" (requires kaleido)\n",
    "):\n",
    "    \"\"\"\n",
    "    Minimal, publication-ready plot of a single role probability across tokens.\n",
    "\n",
    "    - Line mode (default): rolling-smoothed curve (clean trend).\n",
    "    - Points mode: raw per-token probabilities as markers (no smoothing).\n",
    "\n",
    "    Expects columns: role, token_ix, assistant, cot, user, system.\n",
    "    \"\"\"\n",
    "    allowed = {'system', 'user', 'cot', 'assistant'}\n",
    "    if value_col not in allowed:\n",
    "        raise ValueError(f\"value_col must be one of {allowed}, got {value_col!r}\")\n",
    "\n",
    "    line_color = {\n",
    "        \"cot\": \"#0072B2\", # blue\n",
    "        \"assistant\": \"#D55E00\", # vermillion\n",
    "        \"user\": \"#009E73\", # bluish green\n",
    "        \"system\": \"#CC79A7\", # reddish purple\n",
    "    }[value_col]\n",
    "\n",
    "    role_bg = {\n",
    "        \"user\": \"rgba(0,158,115,0.28)\",\n",
    "        \"assistant\": \"rgba(213,94,0,0.24)\",\n",
    "        \"cot\": \"rgba(0,114,178,0.24)\",\n",
    "        \"system\": \"rgba(204,121,167,0.24)\",\n",
    "    }\n",
    "    role_label = {\"user\": \"USER\", \"assistant\": \"ASSISTANT\", \"cot\": \"REASONING\", \"system\": \"SYSTEM\",}\n",
    "    y_label = {\n",
    "        \"cot\": \"CoTness\",\n",
    "        \"assistant\": \"Assistantness\",\n",
    "        \"user\": \"Userness \",\n",
    "        \"system\": \"Systemness   P(role = System)\",\n",
    "    }[value_col]\n",
    "\n",
    "    # Data\n",
    "    df = input_df.copy().sort_values(\"token_in_seq_ix\", kind=\"mergesort\")\n",
    "    x = df[\"token_in_seq_ix\"].to_numpy()\n",
    "    y_raw = df[value_col].to_numpy()\n",
    "    roles = df[\"role\"].to_numpy()\n",
    "\n",
    "    # Rolling smoothing for line mode\n",
    "    if use_points:\n",
    "        y_plot = y_raw  # Points show raw values\n",
    "    else:\n",
    "        y_plot = pd.Series(y_raw).rolling(rolling_window, center=True, min_periods=1).mean().to_numpy()\n",
    "\n",
    "    # Contiguous role regions (actual roles)\n",
    "    regions = []\n",
    "    start = 0\n",
    "    for i in range(1, len(df)):\n",
    "        if roles[i] != roles[i-1]:\n",
    "            regions.append((roles[start], int(x[start]), int(x[i-1])))\n",
    "            start = i\n",
    "    regions.append((roles[start], int(x[start]), int(x[-1])))\n",
    "\n",
    "    # Figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Background bands + labels\n",
    "    for role, x0, x1 in regions:\n",
    "        fig.add_vrect(\n",
    "            x0=x0 - 0.5, x1=x1 + 0.5,\n",
    "            fillcolor=role_bg.get(role, \"rgba(200,200,200,0.22)\"),\n",
    "            line_width=0, layer=\"below\"\n",
    "        )\n",
    "        if x1 - x0 >= 10:\n",
    "            fig.add_annotation(\n",
    "                x=(x0 + x1)/2, y=1.045, xref=\"x\", yref=\"paper\",\n",
    "                text=role_label.get(role, role),\n",
    "                showarrow=False,\n",
    "                font=dict(size=12, color=\"rgba(0,0,0,0.70)\", family=\"Helvetica, Arial, sans-serif\")\n",
    "            )\n",
    "\n",
    "    if use_points:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y_plot, mode=\"markers\",\n",
    "            marker=dict(color=line_color, size=5, opacity=0.85, line=dict(width=0)),\n",
    "            hoverinfo=\"skip\", showlegend=False\n",
    "        ))\n",
    "    else:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y_plot, mode=\"lines\",\n",
    "            line=dict(color=line_color, width=3.6),\n",
    "            hoverinfo=\"skip\", showlegend=False\n",
    "        ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        template=\"simple_white\",\n",
    "        width=1100, height=320,\n",
    "        margin=dict(l=70, r=30, t=64, b=54),\n",
    "        title=dict(text=title, x=0.01, y=0.98, xanchor=\"left\", font=dict(size=20, family=\"Helvetica, Arial, sans-serif\")),\n",
    "        font=dict(size=14, family=\"Helvetica, Arial, sans-serif\"),\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        type = 'log',\n",
    "        # range=[0, 1],\n",
    "        # dtick=0.25,\n",
    "        title_text=y_label, gridcolor=\"rgba(0,0,0,0.06)\")\n",
    "    fig.update_xaxes(title_text=\"Token index\", showgrid=False, zeroline=False)\n",
    "\n",
    "    if export_path:\n",
    "        fig.write_image(export_path, scale=2)\n",
    "\n",
    "    return fig\n",
    "\n",
    "figs = []\n",
    "for tests_variant in test_variant_results:\n",
    "    fig = plot_role_prob_minimal(tests_variant['plot_df'], title = tests_variant['variant'], value_col = 'cot', use_points = True, rolling_window = 5, export_path = None)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b12751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get averages across roles\n",
    "\"\"\"\n",
    "plot_df =redteam_seqs_df.pipe(lambda df: df[df['output_class'].isin(['REFUSAL', 'HARMFUL_RESPONSE'])]).groupby(['redteam_prompt_type', 'output_class']).agg(\n",
    "    count = ('redteam_seq_ix', 'count')\n",
    ").reset_index()\\\n",
    "    .assign(redteam_prompt_type = lambda df: np.where(df['redteam_prompt_type'] == 'synthetic_policy', 'CoT Forgery', df['redteam_prompt_type']))\\\n",
    "    .assign(redteam_prompt_type = lambda df: np.where(df['redteam_prompt_type'] == 'destyled_policy', 'Destyled CoT Forgery', df['redteam_prompt_type']))\\\n",
    "    .assign(redteam_prompt_type = lambda df: np.where(df['redteam_prompt_type'] == 'base', 'Base', df['redteam_prompt_type']))\n",
    "\n",
    "\n",
    "\n",
    "# Convert counts to percentages within each prompt type\n",
    "df_percent = plot_df.copy()\n",
    "df_percent['percent'] = df_percent.groupby('redteam_prompt_type')['count'].transform(lambda x: 100 * x / x.sum())\n",
    "\n",
    "# Plot percentages instead of counts\n",
    "fig = px.bar(\n",
    "    df_percent,\n",
    "    x='redteam_prompt_type',\n",
    "    y='percent',\n",
    "    width = 600,\n",
    "    color='output_class',\n",
    "    barmode='group',\n",
    "    labels={\n",
    "        'redteam_prompt_type': 'Prompt Type',\n",
    "        'percent': 'Percentage (%)',\n",
    "        'output_class': 'Output Class'\n",
    "    },\n",
    "    title='Percentage Distribution of Output Classes by Redteam Prompt Type'\n",
    ")\n",
    "\n",
    "fig.update_layout(template='plotly_white', yaxis=dict(ticksuffix='%'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d961ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Project redteam activations into roles - start with just one sequence\n",
    "\"\"\"\n",
    "# Test sequences - get all variants\n",
    "test_variants = redteam_seqs_df#.pipe(lambda df: df[df['harm_index'] == redteam_seqs_df['harm_index'].tolist()[19]])\n",
    "\n",
    "test_variant_results = []\n",
    "plot_dfs = []\n",
    "for row in tqdm(test_variants.to_records('dict')[0:10]):\n",
    "    seq_samples = redteam_sample_df.pipe(lambda df: df[df['seq_id'] == row['redteam_seq_ix']]).pipe(lambda df: df[df['role'].notna()]).reset_index(drop = True)\n",
    "\n",
    "    seq_hs_cp = cupy.asarray(redteam_all_pre_mlp_hs[test_layer][seq_samples['sample_ix'].tolist(), :])\n",
    "\n",
    "    seq_probs = lr_model.predict_proba(seq_hs_cp).round(6)\n",
    "\n",
    "    # Merge seq probs with inputs\n",
    "    plot_df =\\\n",
    "        pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(cupy.asnumpy(seq_probs), columns = ['user', 'assistant', 'cot', 'system']).clip(1e-6),\n",
    "                seq_samples[['token_in_seq_ix', 'token', 'role']]\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\\\n",
    "        .assign(\n",
    "            variant = row['redteam_prompt_type'],\n",
    "            output_class = row['output_class']\n",
    "        )\n",
    "    \n",
    "    plot_dfs.append(plot_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(plot_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.concat(plot_dfs)\\\n",
    "    .pipe(lambda df: df[df['token_in_seq_ix'] <= 1_000])\\\n",
    "    .groupby(['token_in_seq_ix', 'role', 'variant'], as_index = False).agg(\n",
    "        avg_cotness = ('cot', 'mean')\n",
    "    )\\\n",
    "    .groupby(['variant', 'role'], as_index = False)\\\n",
    "    .agg(\n",
    "        avg_cotness = ('avg_cotness', 'mean')\n",
    "    )\n",
    "\n",
    "# Pivot to Variant x Role matrix and convert to %\n",
    "variant_map = {\n",
    "    \"synthetic_policy\": \"CoT forgery\",\n",
    "    \"destyled_policy\": \"Destyled CoT forgery\",\n",
    "    \"base\": \"Base\",\n",
    "}\n",
    "variant_order = [\"Base\", \"CoT forgery\", \"Destyled CoT forgery\"]\n",
    "role_order = [\"system\", \"user\", \"cot\", \"assistant\"]\n",
    "\n",
    "df = plot_df.copy()\n",
    "df[\"variant_label\"] = df[\"variant\"].map(variant_map).fillna(df[\"variant\"])\n",
    "\n",
    "# Pivot to Variant x Role and convert to %\n",
    "tbl = (df.pivot_table(index=\"variant_label\", columns=\"role\",\n",
    "                      values=\"avg_cotness\", aggfunc=\"mean\")\n",
    "         .reindex(variant_order)\n",
    "         .reindex(columns=role_order))\n",
    "tbl_pct = (tbl * 100).round(1)\n",
    "\n",
    "# --- Lighter color scale for cells ---\n",
    "scale = px.colors.sequential.Blues[:6]  # use lighter half\n",
    "min_v, max_v = np.nanmin(tbl_pct.values), np.nanmax(tbl_pct.values)\n",
    "\n",
    "def val_to_color(v):\n",
    "    if pd.isna(v) or max_v == min_v:\n",
    "        return \"#ffffff\"\n",
    "    t = (v - min_v) / (max_v - min_v)\n",
    "    idx = int(round(t * (len(scale) - 1)))\n",
    "    return scale[idx]\n",
    "\n",
    "# Build column-wise fill colors (first column is the row header)\n",
    "fill_colors = []\n",
    "fill_colors.append([\"#ffffff\"] * len(tbl_pct))  # first column (Variant)\n",
    "for col in tbl_pct.columns:\n",
    "    fill_colors.append([val_to_color(v) for v in tbl_pct[col].tolist()])\n",
    "\n",
    "# Values for display\n",
    "cell_values = [tbl_pct.index.tolist()] + [\n",
    "    [f\"{v:.1f}%\" if pd.notna(v) else \"\" for v in tbl_pct[col]] for col in tbl_pct.columns\n",
    "]\n",
    "\n",
    "# --- Plotly Table (narrower width, lighter header bg) ---\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    columnwidth=[170] + [110] * len(tbl_pct.columns),  # make table less wide\n",
    "    header=dict(\n",
    "        values=[\"Variant\"] + [c.title() for c in tbl_pct.columns],\n",
    "        fill_color=\"#eef3fb\",         # lighter header background\n",
    "        font=dict(color=\"#222\", size=12),\n",
    "        align=\"left\",\n",
    "        height=30\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=cell_values,\n",
    "        fill_color=fill_colors,\n",
    "        align=\"left\",\n",
    "        height=26,\n",
    "        font=dict(size=11, color=\"#222\")\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Avg CoTness by Variant × Role\",\n",
    "    width=680,  # narrower figure\n",
    "    margin=dict(l=10, r=10, t=50, b=10)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2652940",
   "metadata": {},
   "source": [
    "## Role spaces (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eafca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split by roles\n",
    "\"\"\"\n",
    "c4_role_hs = {}\n",
    "c4_role_sample_dfs = {}\n",
    "c4_role_topk_dfs = {}\n",
    "\n",
    "for role in ['system', 'user', 'cot', 'assistant']:\n",
    "    c4_role_sample_dfs[role] = c4_sample_df.pipe(lambda df: df[df['role'] == role]).pipe(lambda df: df[df['is_role_wrapper'] == 0])\n",
    "    c4_role_topk_dfs[role] = c4_topk_df[c4_topk_df['sample_ix'].isin(c4_role_sample_dfs[role]['sample_ix'].tolist())]\n",
    "\n",
    "    # Get corresponding hidden states + cast to f32 for linalg needed for lda\n",
    "    c4_role_hs[role] = {l: c4_all_pre_mlp_hs[l][c4_role_sample_dfs[role]['sample_ix'].tolist(), :].float() for l in c4_all_pre_mlp_hs.keys()}\n",
    "    print(c4_role_hs[role][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_role_plane(states: dict[str, list[torch.Tensor]], target_layer: int = 12, ridge_alpha: float = 1e-3):\n",
    "    \"\"\"\n",
    "    Params\n",
    "        @states: dict with keys {'system', 'user', 'cot', 'assistant'}. Each value is a list over layers; states[r][L] has shape (T, D) with matched token ordering across roles.\n",
    "        @target_layer: layer to use for LDA.\n",
    "        @ridge_alpha: small diagonal added to the pooled within-class covariance.\n",
    "    \"\"\"\n",
    "    roles = ['system', 'user', 'cot', 'assistant']\n",
    "    for r in roles:\n",
    "        assert r in states, f\"Missing role: {r}\"\n",
    "\n",
    "    X = {r: states[r][target_layer].to(dtype=torch.float32) for r in roles}  # (T, D)\n",
    "    T, D = X['assistant'].shape\n",
    "    device = X['assistant'].device\n",
    "\n",
    "    # 1) Content-centering per token across roles (removes shared content identity)\n",
    "    M_token = torch.stack([X[r] for r in roles], dim=0).mean(dim=0)            # (T, D)\n",
    "    Xc = {r: X[r] - M_token for r in roles}\n",
    "\n",
    "    # 2) Pooled within-class covariance (on centered data)\n",
    "    mu = {r: Xc[r].mean(dim=0) for r in roles}                                  # (D,)\n",
    "    residuals = torch.cat([Xc[r] - mu[r] for r in roles], dim=0)                # (4T, D)\n",
    "    cov = (residuals.T @ residuals) / max(1, residuals.shape[0] - len(roles))   # (D, D)\n",
    "    lam = ridge_alpha * (cov.trace() / D)\n",
    "    cov = cov + lam * torch.eye(D, device=device, dtype=cov.dtype)\n",
    "\n",
    "    # 3) Whitening transform: W such that W @ cov @ W^T = I\n",
    "    evals, evecs = torch.linalg.eigh(cov)                                       # ascending\n",
    "    inv_sqrt = torch.diag(torch.rsqrt(evals.clamp_min(1e-12)))\n",
    "    W = (evecs @ inv_sqrt @ evecs.T).to(torch.float32)                           # (D, D)\n",
    "\n",
    "    # 4) Whitened class centroids\n",
    "    mu_w = {r: (Xc[r] @ W.T).mean(dim=0) for r in roles}                        # (D,)\n",
    "\n",
    "    # 5) Define Role Plane axes in whitened space\n",
    "    # Speaker: (assistant-like) vs (non-assistant)\n",
    "    speaker = (mu_w['assistant'] + mu_w['cot'] - mu_w['user'] - mu_w['system']) / 2.0\n",
    "    speaker = speaker / (speaker.norm() + 1e-12)\n",
    "\n",
    "    # CoT: assistant-cot vs assistant-out, orthogonalized to speaker\n",
    "    cot = mu_w['cot'] - mu_w['assistant']\n",
    "    cot = cot - (cot @ speaker) * speaker\n",
    "    cot = cot / (cot.norm() + 1e-12)\n",
    "\n",
    "    P_role = torch.stack([speaker, cot], dim=0)                                  # (2, D)\n",
    "\n",
    "    # 6) Fix axis signs for interpretability (assistant has +speaker; cot>assistant on +cot)\n",
    "    asst_coords = mu_w['assistant'] @ P_role.T\n",
    "    cot_coords  = mu_w['cot']       @ P_role.T\n",
    "    if asst_coords[0] < 0:  # speaker axis\n",
    "        P_role[0] = -P_role[0]\n",
    "    if (cot_coords - asst_coords)[1] < 0:  # cot axis\n",
    "        P_role[1] = -P_role[1]\n",
    "\n",
    "    # 7) Axis standardization stats (z-scores) computed on training tokens\n",
    "    Z_all = torch.cat([(Xc[r] @ W.T) @ P_role.T for r in roles], dim=0)          # (4T, 2)\n",
    "    axis_mean = Z_all.mean(dim=0)\n",
    "    axis_std  = Z_all.std(dim=0).clamp_min(1e-6)\n",
    "\n",
    "    # Global mean as a fallback for unpaired inference (when M_token is unavailable)\n",
    "    M_global = M_token.mean(dim=0)                                              # (D,)\n",
    "\n",
    "    return {\n",
    "        'roles': roles,\n",
    "        'W': W,                   # (D, D) whitening\n",
    "        'P_role': P_role,         # (2, D) rows: [speaker_axis, cot_axis]\n",
    "        'mu_w': mu_w,             # role centroids in whitened space\n",
    "        'axis_mean': axis_mean,   # (2,)\n",
    "        'axis_std': axis_std,     # (2,)\n",
    "        'M_global': M_global,     # (D,)\n",
    "        'dtype': torch.float32,\n",
    "        'device': device,\n",
    "    }\n",
    "    \n",
    "    \n",
    "def project_role_plane(x: torch.Tensor, rp: dict, content_mean: torch.Tensor | None = None):\n",
    "    \"\"\"\n",
    "    Project hidden states x (..., D) into the Role Plane.\n",
    "\n",
    "    content_mean: if you have the *paired* per-token mean across roles (M_token[i]), pass it here for precise content-centering. Otherwise we use rp['M_global'].\n",
    "\n",
    "    Returns:\n",
    "      coords: (..., 2) raw coordinates along (speaker, cot)\n",
    "      zcoords: (..., 2) standardized z-scores along (speaker, cot)\n",
    "    \"\"\"\n",
    "    W, P = rp['W'], rp['P_role']\n",
    "    base = content_mean if content_mean is not None else rp['M_global']\n",
    "    z = (x - base) @ W.T                     # whitened\n",
    "    coords = z @ P.T                         # (..., 2)\n",
    "    zcoords = (coords - rp['axis_mean']) / rp['axis_std']\n",
    "    return coords, zcoords\n",
    "\n",
    "\n",
    "lda = fit_role_plane(c4_role_hs, target_layer = test_layer, ridge_alpha = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variants = redteam_seqs_df.pipe(lambda df: df[df['harm_index'] == redteam_seqs_df['harm_index'].tolist()[0]])\n",
    "\n",
    "test_variant_results = []\n",
    "for row in test_variants.to_records('dict'):\n",
    "    seq_samples = redteam_sample_df.pipe(lambda df: df[df['seq_id'] == row['redteam_seq_ix']]).pipe(lambda df: df[df['role'].notna()]).reset_index(drop = True)\n",
    "\n",
    "    seq_hs_pt = torch.Tensor(redteam_all_pre_mlp_hs[test_layer][seq_samples['sample_ix'].tolist(), :]) # (N, D)\n",
    "    print(seq_hs_pt.shape)\n",
    "    \n",
    "    coords, zcoords = project_role_plane(seq_hs_pt, lda)\n",
    "\n",
    "    # Merge seq probs with inputs\n",
    "    plot_df =\\\n",
    "        pd.concat(\n",
    "            [\n",
    "                pd.DataFrame({\n",
    "                    'speaker_axis': coords[:, 0],\n",
    "                    'channel_axis': coords[:, 1]\n",
    "                }).clip(1e-6),\n",
    "                seq_samples[['token_in_seq_ix', 'token', 'role']]\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "    test_variant_results.append({\n",
    "        'variant': row['redteam_prompt_type'],\n",
    "        'output_class': row['output_class'],\n",
    "        'plot_df': plot_df\n",
    "    })\n",
    "\n",
    "test_variant_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prep_df(df: pd.DataFrame, smoothing: int = 25) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # Expected columns: token_in_seq_ix, token, speaker_axis, channel_axis, role\n",
    "    df = df.sort_values(\"token_in_seq_ix\").reset_index(drop=True)\n",
    "\n",
    "    # Rolling means (centered) for smoother overlay\n",
    "    win = max(1, int(smoothing))\n",
    "    minp = max(1, win // 2)\n",
    "    df[\"speaker_smooth\"] = (\n",
    "        df[\"speaker_axis\"].rolling(win, min_periods=minp, center=True).mean()\n",
    "    )\n",
    "    df[\"channel_smooth\"] = (\n",
    "        df[\"channel_axis\"].rolling(win, min_periods=minp, center=True).mean()\n",
    "    )\n",
    "\n",
    "    # Role boundaries (indices where the role changes)\n",
    "    role_change_mask = df[\"role\"].ne(df[\"role\"].shift(1))\n",
    "    df[\"_role_change\"] = role_change_mask\n",
    "    df[\"_role_start_ix\"] = df.loc[role_change_mask, \"token_in_seq_ix\"]\n",
    "    return df\n",
    "\n",
    "def _add_role_boundaries(fig: go.Figure, df: pd.DataFrame) -> None:\n",
    "    # Draw a vertical line at each role change (skip the very first token)\n",
    "    change_ix = df.loc[df[\"_role_change\"], \"token_in_seq_ix\"].tolist()\n",
    "    for x in change_ix[1:]:\n",
    "        fig.add_vline(x=x, line_dash=\"dash\", opacity=0.25)\n",
    "\n",
    "def _auto_symmetric_range(series_list):\n",
    "    # Symmetric y-range around 0 so the zero-line is centered\n",
    "    vals = np.concatenate([np.asarray(s.dropna().values) for s in series_list if s is not None])\n",
    "    if vals.size == 0:\n",
    "        return None\n",
    "    m = float(np.nanmax(np.abs(vals)))\n",
    "    if m == 0 or np.isnan(m):\n",
    "        return None\n",
    "    pad = 0.05 * m\n",
    "    return [-m - pad, m + pad]\n",
    "\n",
    "def make_role_plane_figures(\n",
    "    df: pd.DataFrame,\n",
    "    smoothing: int = 25,\n",
    "    show_rangeslider: bool = True,\n",
    "    scatter_opacity: float = 0.65,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns three Plotly figures:\n",
    "      (1) fig_speaker_timeline : token index vs speaker_axis (+ rolling mean)\n",
    "      (2) fig_channel_timeline : token index vs channel_axis (+ rolling mean)\n",
    "      (3) fig_role_plane       : 2D scatter of speaker_axis vs channel_axis\n",
    "    \"\"\"\n",
    "    df = _prep_df(df, smoothing)\n",
    "\n",
    "    # ---- 1) Speaker axis over time ----\n",
    "    fig_speaker = px.scatter(\n",
    "        df,\n",
    "        x=\"token_in_seq_ix\",\n",
    "        y=\"speaker_axis\",\n",
    "        color=\"role\",\n",
    "        hover_data={\n",
    "            \"token_in_seq_ix\": True,\n",
    "            \"token\": True,\n",
    "            \"speaker_axis\": \":.3f\",\n",
    "            \"channel_axis\": \":.3f\",\n",
    "            \"role\": True,\n",
    "        },\n",
    "        opacity=scatter_opacity,\n",
    "        category_orders={\"role\": [\"system\", \"user\", \"cot\", \"assistant\"]},\n",
    "        title=\"Speaker axis over sequence (assistant‑ish ↔ non‑assistant)\",\n",
    "    )\n",
    "    fig_speaker.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"token_in_seq_ix\"],\n",
    "            y=df[\"speaker_smooth\"],\n",
    "            mode=\"lines\",\n",
    "            name=f\"rolling mean ({smoothing})\",\n",
    "        )\n",
    "    )\n",
    "    fig_speaker.add_hline(y=0, line_dash=\"dot\")\n",
    "    _add_role_boundaries(fig_speaker, df)\n",
    "    yr = _auto_symmetric_range([df[\"speaker_axis\"], df[\"speaker_smooth\"]])\n",
    "    if yr is not None:\n",
    "        fig_speaker.update_yaxes(range=yr)\n",
    "    fig_speaker.update_layout(\n",
    "        xaxis_title=\"Token index in sequence\",\n",
    "        yaxis_title=\"Speaker axis\",\n",
    "        hovermode=\"x unified\",\n",
    "        legend_title_text=\"Role\",\n",
    "    )\n",
    "    if show_rangeslider:\n",
    "        fig_speaker.update_layout(xaxis_rangeslider_visible=True)\n",
    "\n",
    "    # ---- 2) Channel/CoT axis over time ----\n",
    "    fig_channel = px.scatter(\n",
    "        df,\n",
    "        x=\"token_in_seq_ix\",\n",
    "        y=\"channel_axis\",\n",
    "        color=\"role\",\n",
    "        hover_data={\n",
    "            \"token_in_seq_ix\": True,\n",
    "            \"token\": True,\n",
    "            \"speaker_axis\": \":.3f\",\n",
    "            \"channel_axis\": \":.3f\",\n",
    "            \"role\": True,\n",
    "        },\n",
    "        opacity=scatter_opacity,\n",
    "        category_orders={\"role\": [\"system\", \"user\", \"cot\", \"assistant\"]},\n",
    "        title=\"CoT / channel axis over sequence (assistant‑CoT ↔ assistant‑final)\",\n",
    "    )\n",
    "    fig_channel.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"token_in_seq_ix\"],\n",
    "            y=df[\"channel_smooth\"],\n",
    "            mode=\"lines\",\n",
    "            name=f\"rolling mean ({smoothing})\",\n",
    "        )\n",
    "    )\n",
    "    fig_channel.add_hline(y=0, line_dash=\"dot\")\n",
    "    _add_role_boundaries(fig_channel, df)\n",
    "    yr = _auto_symmetric_range([df[\"channel_axis\"], df[\"channel_smooth\"]])\n",
    "    if yr is not None:\n",
    "        fig_channel.update_yaxes(range=yr)\n",
    "    fig_channel.update_layout(\n",
    "        xaxis_title=\"Token index in sequence\",\n",
    "        yaxis_title=\"CoT / channel axis\",\n",
    "        hovermode=\"x unified\",\n",
    "        legend_title_text=\"Role\",\n",
    "    )\n",
    "    if show_rangeslider:\n",
    "        fig_channel.update_layout(xaxis_rangeslider_visible=True)\n",
    "\n",
    "    # ---- 3) 2‑D Role Plane scatter ----\n",
    "    fig_plane = px.scatter(\n",
    "        df,\n",
    "        x=\"speaker_axis\",\n",
    "        y=\"channel_axis\",\n",
    "        color=\"role\",\n",
    "        hover_data={\n",
    "            \"token_in_seq_ix\": True,\n",
    "            \"token\": True,\n",
    "            \"speaker_axis\": \":.3f\",\n",
    "            \"channel_axis\": \":.3f\",\n",
    "            \"role\": True,\n",
    "        },\n",
    "        opacity=scatter_opacity,\n",
    "        category_orders={\"role\": [\"system\", \"user\", \"cot\", \"assistant\"]},\n",
    "        title=\"Role Plane (x: speaker axis, y: CoT/channel axis)\",\n",
    "    )\n",
    "    fig_plane.add_vline(x=0, line_dash=\"dot\")\n",
    "    fig_plane.add_hline(y=0, line_dash=\"dot\")\n",
    "    fig_plane.update_layout(\n",
    "        xaxis_title=\"Speaker axis\",\n",
    "        yaxis_title=\"CoT / channel axis\",\n",
    "        legend_title_text=\"Role\",\n",
    "    )\n",
    "\n",
    "    return fig_speaker, fig_channel, fig_plane\n",
    "\n",
    "# --- Example usage (uncomment to run) ---\n",
    "fig_speaker, fig_channel, fig_plane = make_role_plane_figures(test_variant_results[0]['plot_df'], smoothing=25)\n",
    "fig_speaker.show()\n",
    "fig_channel.show()\n",
    "fig_plane.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_role_prob_minimal(\n",
    "    input_df: pd.DataFrame,\n",
    "    *,\n",
    "    title: str = '',\n",
    "    value_col: str = \"cot\", # one of: 'cot','assistant','user','system'\n",
    "    rolling_window: int = 35, # used for line mode only\n",
    "    use_points: bool = False, # True -> markers (raw), False -> line (smoothed)\n",
    "    export_path: str = None # e.g. \"figure.svg\" (requires kaleido)\n",
    "):\n",
    "    \"\"\"\n",
    "    Minimal, publication-ready plot of a single role probability across tokens.\n",
    "\n",
    "    - Line mode (default): rolling-smoothed curve (clean trend).\n",
    "    - Points mode: raw per-token probabilities as markers (no smoothing).\n",
    "\n",
    "    Expects columns: role, token_ix, assistant, cot, user, system.\n",
    "    \"\"\"\n",
    "    allowed = {'system', 'user', 'cot', 'assistant'}\n",
    "    if value_col not in allowed:\n",
    "        raise ValueError(f\"value_col must be one of {allowed}, got {value_col!r}\")\n",
    "\n",
    "    line_color = {\n",
    "        \"cot\": \"#0072B2\",  # blue\n",
    "        \"assistant\": \"#D55E00\",  # vermillion\n",
    "        \"user\": \"#009E73\",  # bluish green\n",
    "        \"system\": \"#CC79A7\",  # reddish purple\n",
    "    }[value_col]\n",
    "\n",
    "    role_bg = {\n",
    "        \"user\": \"rgba(0,158,115,0.28)\",\n",
    "        \"assistant\": \"rgba(213,94,0,0.24)\",\n",
    "        \"cot\": \"rgba(0,114,178,0.24)\",\n",
    "        \"system\": \"rgba(204,121,167,0.24)\",\n",
    "    }\n",
    "    role_label = {\"user\": \"USER\", \"assistant\": \"ASSISTANT\", \"cot\": \"REASONING\", \"system\": \"SYSTEM\",}\n",
    "    y_label = {\n",
    "        \"cot\": \"less ←       CoTness       ⟶ more\",\n",
    "        \"assistant\": \"Assistantness\",\n",
    "        \"user\": \"Userness \",\n",
    "        \"system\": \"Systemness   P(role = System)\",\n",
    "    }[value_col]\n",
    "\n",
    "    # Data\n",
    "    df = input_df.copy().sort_values(\"token_in_seq_ix\", kind=\"mergesort\")\n",
    "    x = df[\"token_in_seq_ix\"].to_numpy()\n",
    "    y_raw = df[value_col].to_numpy()\n",
    "    roles = df[\"role\"].to_numpy()\n",
    "\n",
    "    # Rolling smoothing for line mode\n",
    "    if use_points:\n",
    "        y_plot = y_raw  # Points show raw values\n",
    "    else:\n",
    "        y_plot = pd.Series(y_raw).rolling(rolling_window, center=True, min_periods=1).mean().to_numpy()\n",
    "\n",
    "    # Contiguous role regions (actual roles)\n",
    "    regions = []\n",
    "    start = 0\n",
    "    for i in range(1, len(df)):\n",
    "        if roles[i] != roles[i-1]:\n",
    "            regions.append((roles[start], int(x[start]), int(x[i-1])))\n",
    "            start = i\n",
    "    regions.append((roles[start], int(x[start]), int(x[-1])))\n",
    "\n",
    "    # Figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Background bands + labels\n",
    "    for role, x0, x1 in regions:\n",
    "        fig.add_vrect(\n",
    "            x0=x0 - 0.5, x1=x1 + 0.5,\n",
    "            fillcolor=role_bg.get(role, \"rgba(200,200,200,0.22)\"),\n",
    "            line_width=0, layer=\"below\"\n",
    "        )\n",
    "        if x1 - x0 >= 10:\n",
    "            fig.add_annotation(\n",
    "                x=(x0 + x1)/2, y=1.045, xref=\"x\", yref=\"paper\",\n",
    "                text=role_label.get(role, role),\n",
    "                showarrow=False,\n",
    "                font=dict(size=12, color=\"rgba(0,0,0,0.70)\", family=\"Helvetica, Arial, sans-serif\")\n",
    "            )\n",
    "\n",
    "    if use_points:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y_plot, mode=\"markers\",\n",
    "            marker=dict(color=line_color, size=5, opacity=0.85, line=dict(width=0)),\n",
    "            hoverinfo=\"skip\", showlegend=False\n",
    "        ))\n",
    "    else:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y_plot, mode=\"lines\",\n",
    "            line=dict(color=line_color, width=3.6),\n",
    "            hoverinfo=\"skip\", showlegend=False\n",
    "        ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        template=\"simple_white\",\n",
    "        width=1100, height=420,\n",
    "        margin=dict(l=70, r=30, t=64, b=54),\n",
    "        title=dict(text=title, x=0.01, y=0.98, xanchor=\"left\", font=dict(size=20, family=\"Helvetica, Arial, sans-serif\")),\n",
    "        font=dict(size=14, family=\"Helvetica, Arial, sans-serif\"),\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        # type = 'log',\n",
    "        # range=[0, 20],\n",
    "        # dtick=0.25,\n",
    "        title_text=y_label, gridcolor=\"rgba(0,0,0,0.06)\")\n",
    "    fig.update_xaxes(title_text=\"Token index\", showgrid=False, zeroline=False)\n",
    "\n",
    "    if export_path:\n",
    "        fig.write_image(export_path, scale=2)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "figs = []\n",
    "for tests_variant in test_variant_results:\n",
    "    fig = plot_role_prob_minimal(tests_variant['plot_df'], title = tests_variant['variant'], value_col = 'cot', use_points = True, export_path = None)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
