{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beade33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test role confusion with hidden states\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy\n",
    "import cuml\n",
    "import importlib\n",
    "import gc\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from utils.memory import check_memory, clear_all_cuda_memory\n",
    "from utils.role_assignments import label_content_roles\n",
    "from utils.store_outputs import convert_outputs_to_df_fast\n",
    "\n",
    "main_device = 'cuda:0'\n",
    "seed = 1234\n",
    "\n",
    "clear_all_cuda_memory()\n",
    "check_memory()\n",
    "\n",
    "ws = '/workspace/deliberative-alignment-jailbreaks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26db3f",
   "metadata": {},
   "source": [
    "## Load models & data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75666ea5",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80af64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the base tokenizer/model\n",
    "\"\"\"\n",
    "selected_model_index = 1\n",
    "\n",
    "def get_model(index):\n",
    "    # HF model ID, model prefix, model architecture,  attn implementation, whether to use hf lib implementation\n",
    "    models = {\n",
    "        0: ('openai/gpt-oss-120b', 'gptoss120', 'gptoss', 'kernels-community/vllm-flash-attn3', True, 36), # Will load experts in MXFP4 if triton kernels installed\n",
    "        1: ('openai/gpt-oss-20b', 'gptoss20', 'gptoss', 'kernels-community/vllm-flash-attn3', True, 24),\n",
    "        2: ('Qwen/Qwen3-30B-A3B-Thinking-2507', 'qwen3moe', 'qwen3moe', None, True, 48)\n",
    "    }\n",
    "    return models[index]\n",
    "\n",
    "def load_model_and_tokenizer(model_id, model_prefix, model_attn, model_use_hf):\n",
    "    \"\"\"\n",
    "    Load the model and tokenizer from HF, or from file if already downloaded.\n",
    "    \"\"\"\n",
    "    cache_dir = '/workspace/hf'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir = cache_dir, add_eos_token = False, add_bos_token = False, padding_side = 'left', trust_remote_code = True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir = cache_dir, dtype = torch.bfloat16, trust_remote_code = not model_use_hf, device_map = 'auto', attn_implementation = model_attn).eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "model_id, model_prefix, model_architecture, model_attn, model_use_hf, model_n_layers = get_model(selected_model_index)\n",
    "tokenizer, model = load_model_and_tokenizer(model_id, model_prefix, model_attn, model_use_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11e85b",
   "metadata": {},
   "source": [
    "### Load c4 role activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0533d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load dataset\n",
    "\"\"\"\n",
    "def load_data(folder_path, model_prefix, max_data_files):\n",
    "    \"\"\"\n",
    "    Load data saved by `export-activations.ipynb`\n",
    "    \"\"\"\n",
    "    folders = [f'{ws}/experiments/role-confusion/{folder_path}/{model_prefix}/{i:02d}' for i in range(max_data_files)]\n",
    "    folders = [f for f in folders if os.path.isdir(f)]\n",
    "\n",
    "    all_pre_mlp_hs = []\n",
    "    sample_df = []\n",
    "    topk_df = []\n",
    "\n",
    "    for f in tqdm(folders):\n",
    "        sample_df.append(pd.read_pickle(f'{f}/samples.pkl'))\n",
    "        topk_df.append(pd.read_pickle(f'{f}/topks.pkl'))\n",
    "        all_pre_mlp_hs.append(torch.load(f'{f}/all-pre-mlp-hidden-states.pt'))\n",
    "\n",
    "    sample_df = pd.concat(sample_df)\n",
    "    topk_df = pd.concat(topk_df)\n",
    "    all_pre_mlp_hs = torch.concat(all_pre_mlp_hs)    \n",
    "\n",
    "    with open(f'{ws}/experiments/role-confusion/{folder_path}/{model_prefix}/metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    gc.collect()\n",
    "    return sample_df, topk_df, all_pre_mlp_hs, metadata['all_pre_mlp_hidden_states_layers']\n",
    "\n",
    "sample_df_import, topk_df_import, all_pre_mlp_hs_import, act_map = load_data('activations', model_prefix, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b16af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils.role_assignments\n",
    "importlib.reload(utils.role_assignments)\n",
    "label_content_roles = utils.role_assignments.label_content_roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the valid role assignments function label_content_roles\n",
    "\"\"\"\n",
    "s = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {'role': 'system', 'content': 'Test.'},\n",
    "        {'role': 'user', 'content': 'Hi! I am a dog and I like to bark'},\n",
    "        {'role': 'assistant', 'content': 'I am a dog and I like to bark'}\n",
    "    ],\n",
    "    tokenize = False,\n",
    "    padding = 'max_length',\n",
    "    truncation = True,\n",
    "    max_length = 512,\n",
    "    add_generation_prompt = False\n",
    ")\n",
    "\n",
    "z =\\\n",
    "    pd.DataFrame({'input_ids': tokenizer(s)['input_ids']})\\\n",
    "    .assign(token = lambda df: tokenizer.convert_ids_to_tokens(df['input_ids']))\\\n",
    "    .assign(prompt_ix = 0, batch_ix = 0, sequence_ix = 0, token_ix = lambda df: df.index)\n",
    "\n",
    "label_content_roles(model_architecture, z).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's clean up the mappings here. We'll get everything to a sample_ix level first. We'll also flag the role wrapper tokens. Drop nothing. \n",
    "\"\"\"\n",
    "def clean_mappings(model_architecture, sample_df_import, topk_df_import):\n",
    "\n",
    "    # We'll read the role mappings the raw way, instead of just using the input_mappings file. Then we can re-use the same logic for later on.\n",
    "    # Technically this could be done easily with the input_mappings file (.merge(input_mappings[['prompt_ix', 'question_ix', 'role']], how = 'left', on = ['prompt_ix'])\\),\n",
    "    # but this is more robust, and doesn't assume one role per sequence/prompt_ix.\n",
    "    # input_mappings = pd.read_csv(f'{folder_path}/{model_prefix}/input_mappings.csv')\n",
    "\n",
    "    sample_df_raw =\\\n",
    "        label_content_roles(model_architecture, sample_df_import)\\\n",
    "        .assign(sample_ix = lambda df: df.groupby(['batch_ix', 'sequence_ix', 'token_ix']).ngroup())\\\n",
    "        .assign(token_in_seq_ix = lambda df: df.groupby(['prompt_ix']).cumcount())\\\n",
    "        .assign(token_in_role_ix = lambda df: df.groupby(['prompt_ix', 'role']).cumcount())\n",
    "\n",
    "    c4_topk_df =\\\n",
    "        topk_df_import\\\n",
    "        .merge(sample_df_raw[['sample_ix', 'prompt_ix', 'batch_ix', 'sequence_ix', 'token_ix']], how = 'inner', on = ['sequence_ix', 'token_ix', 'batch_ix'])\\\n",
    "        .drop(columns = ['sequence_ix', 'token_ix', 'batch_ix'])\n",
    "\n",
    "    c4_sample_df =\\\n",
    "        sample_df_raw\\\n",
    "        .drop(columns = ['batch_ix', 'sequence_ix'])\n",
    "\n",
    "    return c4_sample_df, c4_topk_df\n",
    "\n",
    "sample_df, topk_df = clean_mappings(model_architecture, sample_df_import, topk_df_import)\n",
    "del sample_df_import, topk_df_import\n",
    "\n",
    "gc.collect()\n",
    "display(sample_df)\n",
    "display(topk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81cc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert activations to fp16 (for compatibility with cupy later) + layer-wise dict\n",
    "\"\"\"\n",
    "all_pre_mlp_hs = all_pre_mlp_hs_import.to(torch.float16)\n",
    "# compare_bf16_fp16_batched(all_pre_mlp_hs_import, all_pre_mlp_hs)\n",
    "del all_pre_mlp_hs_import\n",
    "all_pre_mlp_hs = {layer_ix: all_pre_mlp_hs[:, save_ix, :] for save_ix, layer_ix in enumerate(act_map)}\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc62db",
   "metadata": {},
   "source": [
    "## Role spaces (logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac139eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run logistic regression on c4 to get a model for role predictions\n",
    "\"\"\"\n",
    "def run_lr(x_cp, y_cp):\n",
    "    x_train, x_test, y_train, y_test = cuml.train_test_split(x_cp, y_cp, test_size = 0.2, random_state = 123)\n",
    "    lr_model = cuml.linear_model.LogisticRegression(penalty = 'l2', C = 0.0001, max_iter = 1000, fit_intercept = True)\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    accuracy = lr_model.score(x_test, y_test)\n",
    "    return lr_model, accuracy\n",
    "\n",
    "test_layer = round(model_n_layers * .75)\n",
    "print(f\"Test layer: {test_layer}\")\n",
    "label_to_id = {'system': 0, 'user': 1, 'assistant-cot': 2, 'assistant-final': 3}\n",
    "# label_to_id = {'system': 0, 'user': 1, 'assistant-cot': 2, 'assistant-final': 3, 'tool': 4}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "valid_sample_ix =\\\n",
    "    sample_df\\\n",
    "    .pipe(lambda df: df[(df['in_content_span'] == True) & (df['role'].notna()) & (df['role'].isin(list(label_to_id.keys())))])\\\n",
    "    ['sample_ix'].tolist()\\\n",
    "\n",
    "role_labels = [\n",
    "    label_to_id[role]\n",
    "    for role in sample_df[sample_df['sample_ix'].isin(valid_sample_ix)]['role'].tolist()\n",
    "]\n",
    "\n",
    "role_labels_cp = cupy.asarray(role_labels)\n",
    "x_cp = cupy.asarray(all_pre_mlp_hs[test_layer][valid_sample_ix, :].to(torch.float16).detach().cpu())\n",
    "lr_model, test_acc = run_lr(x_cp, role_labels_cp)\n",
    "\n",
    "print(test_acc)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d30b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll test some projections of different sequences\n",
    "\"\"\"\n",
    "from utils.dataset import ReconstructableTextDataset, stack_collate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "base_messages = [\n",
    "    # User-like question\n",
    "    \"In a few sentences, how do I grow tomatoes indoors?\",\n",
    "    # Assistant-CoT style\n",
    "    \"We need to answer: In a few sentences, how to grow tomatoes indoors. Provide concise steps: choose a container, potting mix, sun or grow lights, watering, fertilizing, staking, pollination. Should mention location, temperature, etc. Should be short. Let's produce ~5-6 sentences.\",\n",
    "    # Assistant-final style\n",
    "    \"Use a 30–35 cm (12‑14 in) pot with durable drainage and fill it with a high‑quality, well‑draining potting mix (½ soil, ¼ perlite, ¼ peat or coconut coir). Plant a small‑seeding or a pre‑grown dwarf or determinate tomato cone, and keep the pot in a south‑facing windowsill or, better, under 12–16 h/day of bright LED or HPS grow lights at 50–80 cm distance. Maintain 18–24 °C (65–75 °F) day temperatures, 12–15 °C night temperatures, and water when the top 1 cm of soil feels dry, using a balanced 10‑20‑10 NPK fertilizer every 2–3 weeks. Space the plant with a stake or cage, trim suckers, and to aid pollination, gently shake or use a small fan to keep air moving. Once fruit sets, keep the plant in a warm, well‑ventilated area, watching for blossom end rot (ensure adequate calcium) and harvesting as tomatoes ripen.\",\n",
    "    # User-like question\n",
    "    \"Oh, thanks!! Is it easier to grow them indoors or outdoors?\"\n",
    "]\n",
    "\n",
    "base_prompt = f\"{base_messages[0]}\\n{base_messages[1]}\\n{base_messages[2]}\\n{base_messages[3]}\"\n",
    "\n",
    "prompts = {}\n",
    "if model_architecture == 'gptoss':\n",
    "    prompts[0] = f\"You are ChatGPT, a large language model trained by OpenAI.\\nKnowledge cutoff: 2024-06\\nCurrent date: 2025-10-06\\n\\nReasoning: medium\\n\\n# Valid channels: analysis, commentary, final. Channel must be included for every message.\\n{base_prompt}\"\n",
    "else:\n",
    "    prompts[0] = base_prompt\n",
    "    \n",
    "prompts[1] = tokenizer.apply_chat_template(\n",
    "    [{'role': 'user', 'content': base_prompt}],\n",
    "    tokenize = False, add_generation_prompt = False\n",
    ")\n",
    "\n",
    "prompts[2] = tokenizer.apply_chat_template(\n",
    "    [{'role': 'assistant', 'content': base_prompt}],\n",
    "    tokenize = False, add_generation_prompt = False\n",
    ")\n",
    "\n",
    "if model_architecture == 'gptoss':\n",
    "    prompts[3] = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {'role': 'user', 'content': base_messages[0]},\n",
    "            {'role': 'assistant', 'content': f\"<think>\\n{base_messages[1]}\\n</think>\\n{base_messages[2]}\"},\n",
    "            {'role': 'user', 'content': base_messages[3]}\n",
    "        ],\n",
    "        tokenize = False, add_generation_prompt = False\n",
    "    )\n",
    "elif model_architecture == 'qwen3moe':\n",
    "    prompts[3] = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {'role': 'user', 'content': base_messages[0]},\n",
    "            {'role': 'assistant', 'content': f\"<think>{base_messages[1]}</think>{base_messages[2]}\"},\n",
    "            {'role': 'user', 'content': base_messages[3]}\n",
    "        ],\n",
    "\n",
    "    )\n",
    "\n",
    "test_seqs =\\\n",
    "    pd.DataFrame({'prompt': [p for _, p in prompts.items()]})\\\n",
    "    .assign(prompt_ix = lambda df: list(range(0, len(df))))\n",
    "\n",
    "# Create and chunk into lists of size 500 each - these will be the export breaks\n",
    "test_dl = DataLoader(\n",
    "    ReconstructableTextDataset(test_seqs['prompt'].tolist(), tokenizer, max_length = 512, prompt_ix = test_seqs['prompt_ix'].tolist()),\n",
    "    batch_size = 16,\n",
    "    shuffle = False,\n",
    "    collate_fn = stack_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4cabfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run forward passes\n",
    "\"\"\"\n",
    "model_module = importlib.import_module(f\"utils.pretrained_models.{model_architecture}\")\n",
    "run_model_return_topk = getattr(model_module, f\"run_{model_architecture}_return_topk\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_and_export_states(model, dl: ReconstructableTextDataset, layers_to_keep_acts: list[int]):\n",
    "    \"\"\"\n",
    "    Run forward passes on given model and store the decomposed sample_df plus hidden states\n",
    "\n",
    "    Params:\n",
    "        @model: The model to run forward passes on. Should return a dict with keys `logits`, `all_topk_experts`, `all_topk_weights`,\n",
    "          `all_pre_mlp_hidden_states`, and `all_expert_outputs`.\n",
    "        @dl: A ReconstructableTextDataset of which returns `input_ids`, `attention_mask`, and `original_tokens`.\n",
    "        @layers_to_keep_acts: A list of layer indices (0-indexed) for which to filter `all_pre_mlp_hidden_states` (see returned object description).\n",
    "\n",
    "    Returns:\n",
    "        A dict with keys:\n",
    "        - `sample_df`: A sample (token)-level dataframe with corresponding input token ID, output token ID, and input token text (removes masked tokens)\n",
    "        - `all_pre_mlp_hidden_states`: A tensor of size n_samples x layers_to_keep_acts x D return the hidden state for each retained layers. Each \n",
    "            n_sample corresponds to a row of sample_df.\n",
    "    \"\"\"\n",
    "    all_pre_mlp_hidden_states = []\n",
    "    sample_dfs = []\n",
    "\n",
    "    for batch_ix, batch in tqdm(enumerate(dl), total = len(dl)):\n",
    "\n",
    "        input_ids = batch['input_ids'].to(main_device)\n",
    "        attention_mask = batch['attention_mask'].to(main_device)\n",
    "        original_tokens = batch['original_tokens']\n",
    "        prompt_indices = batch['prompt_ix']\n",
    "\n",
    "        output = run_model_return_topk(model, input_ids, attention_mask, return_hidden_states = True)\n",
    "\n",
    "        # Check no bugs by validating output/perplexity\n",
    "        if batch == 0:\n",
    "            loss = ForCausalLMLoss(output['logits'], torch.where(input_ids == tokenizer.pad_token_id, torch.tensor(-100), input_ids), model.config.vocab_size).detach().cpu().item()\n",
    "            for i in range(min(20, input_ids.size(0))):\n",
    "                decoded_input = tokenizer.decode(input_ids[i, :], skip_special_tokens = False)\n",
    "                next_token_id = torch.argmax(output['logits'][i, -1, :]).item()\n",
    "                print('---------\\n' + decoded_input + colored(tokenizer.decode([next_token_id], skip_special_tokens = False).replace('\\n', '<lb>'), 'green'))\n",
    "            print(f\"PPL:\", torch.exp(torch.tensor(loss)).item())\n",
    "                \n",
    "        original_tokens_df = pd.DataFrame(\n",
    "            [(seq_i, tok_i, tok) for seq_i, tokens in enumerate(original_tokens) for tok_i, tok in enumerate(tokens)], \n",
    "            columns = ['sequence_ix', 'token_ix', 'token']\n",
    "        )\n",
    "                \n",
    "        prompt_indices_df = pd.DataFrame(\n",
    "            [(seq_i, seq_source) for seq_i, seq_source in enumerate(prompt_indices)], \n",
    "            columns = ['sequence_ix', 'prompt_ix']\n",
    "        )\n",
    "\n",
    "        # Create sample (token) level dataframe\n",
    "        sample_df =\\\n",
    "            convert_outputs_to_df_fast(input_ids, attention_mask, output['logits'])\\\n",
    "            .merge(original_tokens_df, how = 'left', on = ['token_ix', 'sequence_ix'])\\\n",
    "            .merge(prompt_indices_df, how = 'left', on = ['sequence_ix'])\\\n",
    "            .assign(batch_ix = batch_ix)\n",
    "        \n",
    "        sample_dfs.append(sample_df)\n",
    "\n",
    "        # Store pre-MLP hidden states - the fwd pass as n_layers list as BN x D, collapse to BN x n_layers x D, with BN filtering out masked items\n",
    "        valid_pos = torch.where(attention_mask.cpu().view(-1) == 1) # Valid (BN, ) positions\n",
    "        all_pre_mlp_hidden_states.append(torch.stack(output['all_pre_mlp_hidden_states'], dim = 1)[valid_pos][:, layers_to_keep_acts, :])\n",
    "\n",
    "        batch_ix += 1\n",
    "\n",
    "    sample_df = pd.concat(sample_dfs, ignore_index = True)\n",
    "    all_pre_mlp_hidden_states = torch.cat(all_pre_mlp_hidden_states, dim = 0)\n",
    "\n",
    "    return {\n",
    "        'sample_df': sample_df,\n",
    "        'all_pre_mlp_hs': all_pre_mlp_hidden_states\n",
    "    }\n",
    "\n",
    "test_outputs = run_and_export_states(\n",
    "    model,\n",
    "    test_dl,\n",
    "    layers_to_keep_acts = list(range(model_n_layers))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56da9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare sample df\n",
    "\"\"\"\n",
    "test_sample_df =\\\n",
    "    test_outputs['sample_df'].merge(test_seqs, on = 'prompt_ix', how = 'inner')\\\n",
    "    .assign(sample_ix = lambda df: df.groupby(['batch_ix', 'sequence_ix', 'token_ix']).ngroup())\\\n",
    "    .assign(token_in_seq_ix = lambda df: df.groupby(['prompt_ix']).cumcount())#\\\n",
    "    # .assign(token_in_role_ix = lambda df: df.groupby(['prompt_ix', 'role']).cumcount())\n",
    "\n",
    "display(test_sample_df)\n",
    "\n",
    "test_pre_mlp_hs = test_outputs['all_pre_mlp_hs'].to(torch.float16)\n",
    "test_pre_mlp_hs = {layer_ix: test_pre_mlp_hs[:, save_ix, :] for save_ix, layer_ix in enumerate(act_map)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_df_labeled =\\\n",
    "    test_sample_df\\\n",
    "    .sort_values(['prompt_ix', 'token_ix'])\\\n",
    "    .assign(\n",
    "        _t1 = lambda d: d.groupby('prompt_ix')['token'].shift(-1),\n",
    "        _t2 = lambda d: d.groupby('prompt_ix')['token'].shift(-2),\n",
    "        _t3 = lambda d: d.groupby('prompt_ix')['token'].shift(-3),\n",
    "        _t4 = lambda d: d.groupby('prompt_ix')['token'].shift(-4),\n",
    "        _t5 = lambda d: d.groupby('prompt_ix')['token'].shift(-5),\n",
    "        _b1 = lambda d: d.groupby('prompt_ix')['token'].shift(1),\n",
    "        _b2 = lambda d: d.groupby('prompt_ix')['token'].shift(2),\n",
    "        _b3 = lambda d: d.groupby('prompt_ix')['token'].shift(3),\n",
    "        _b4 = lambda d: d.groupby('prompt_ix')['token'].shift(4),\n",
    "        _b5 = lambda d: d.groupby('prompt_ix')['token'].shift(5),\n",
    "    )\\\n",
    "    .assign(\n",
    "        tok_roll = lambda d: d['token'].fillna('') + d['_t1'].fillna('') + d['_t2'].fillna('') + d['_t3'].fillna('') + d['_t4'].fillna('') + d['_t5'].fillna(''),\n",
    "        tok_back = lambda d: d['_b5'].fillna('') + d['_b4'].fillna('') + d['_b3'].fillna('') + d['_b2'].fillna('') + d['_b1'].fillna('') + d['token'].fillna('')\n",
    "    )\\\n",
    "    .drop(columns=['_t1','_t2','_t3','_t4','_t5','_b1','_b2','_b3','_b4','_b5'])\\\n",
    "    .pipe(lambda d: d.join(\n",
    "        pd.concat(\n",
    "            [\n",
    "                (\n",
    "                    d['tok_roll'].apply(lambda s, t=t: bool(s) and (s in t)) |\n",
    "                    d['tok_back'].apply(lambda s, t=t: bool(s) and (s in t))\n",
    "                ).rename(f'hit_p{i}')\n",
    "                for i, t in enumerate(base_messages)\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    ))\\\n",
    "    .assign(\n",
    "        base_ix = lambda d: np.select(\n",
    "            [d[f'hit_p{i}'] for i in range(len(base_messages))],\n",
    "            list(range(len(base_messages))),\n",
    "            default=np.nan\n",
    "        ),\n",
    "        ambiguous = lambda d: d[[f'hit_p{i}' for i in range(len(base_messages))]].sum(axis=1) > 1,\n",
    "        base_name = lambda d: d['base_ix'].map({i: f\"p{i}\" for i in range(len(base_messages))})\n",
    "    )\\\n",
    "    .drop(columns=[f'hit_p{i}' for i in range(len(base_messages))])\\\n",
    "    .drop(columns=['tok_roll', 'tok_back'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07198ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Project into rolespace - all\n",
    "\"\"\"\n",
    "project_test_sample_df = test_sample_df_labeled\n",
    "project_hs_cp = cupy.asarray(test_pre_mlp_hs[test_layer][project_test_sample_df['sample_ix'].tolist(), :])\n",
    "project_probs = lr_model.predict_proba(project_hs_cp).round(6)\n",
    "\n",
    "# Merge seq probs with inputs\n",
    "plot_df =\\\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(cupy.asnumpy(project_probs), columns = list(label_to_id.keys())).clip(1e-6),\n",
    "            project_test_sample_df[['sample_ix', 'prompt_ix', 'token', 'token_in_seq_ix', 'base_name']]\n",
    "        ],\n",
    "        axis = 1\n",
    "    )\n",
    "\n",
    "plot_df = plot_df.melt(id_vars = ['sample_ix', 'prompt_ix', 'token', 'token_in_seq_ix', 'base_name'], var_name = 'role_space', value_name = 'prob')\n",
    "\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot tests\n",
    "\"\"\"\n",
    "facet_order = list(label_to_id.keys())\n",
    "\n",
    "smooth_df =\\\n",
    "    plot_df\\\n",
    "    .sort_values('sample_ix')\\\n",
    "    .assign(\n",
    "        prob_sma = lambda df: df.groupby(['prompt_ix', 'role_space'])['prob'].rolling(window = 2, min_periods = 1).mean().reset_index(level = [0, 1], drop = True),\n",
    "        prob_ewma = lambda df: df.groupby(['prompt_ix', 'role_space'])['prob'].ewm(alpha = .9, min_periods = 1).mean().reset_index(level = [0, 1], drop = True)\n",
    "    )\n",
    "\n",
    "for prompt_ix in smooth_df['prompt_ix'].unique().tolist():\n",
    "    this_df = smooth_df.pipe(lambda df: df[df['prompt_ix'] == prompt_ix])\n",
    "    fig = px.scatter(\n",
    "        this_df, x = 'sample_ix', y = 'prob',\n",
    "        facet_row = 'role_space',\n",
    "        color = this_df['base_name'].astype(str),\n",
    "        category_orders = {'role_space': facet_order},\n",
    "        hover_name = 'token',\n",
    "        hover_data = {\n",
    "            'prob': ':.3f'\n",
    "        },\n",
    "        # markers = True,\n",
    "        title = f'prompt_ix = {str(prompt_ix)}',\n",
    "        labels = {\n",
    "            'sample_ix': 'Sample',\n",
    "            'prob': 'Prob',\n",
    "            'prob_smoothed': 'Smoothed Prob',\n",
    "            'role_space': 'role_space'\n",
    "        }\n",
    "    ).update_yaxes(\n",
    "        range = [0, 1],\n",
    "        side = 'left'\n",
    "    ).update_layout(height = 600, width = 800)\n",
    "\n",
    "    def pretty(a):\n",
    "        a.update(\n",
    "            text = a.text.split(\"=\")[-1],\n",
    "            x = 0.5, xanchor = \"center\",\n",
    "            y = a.y + 0.08,\n",
    "            textangle = 0,\n",
    "            font = dict(size = 12),\n",
    "            bgcolor = 'rgba(255, 255, 255, 0.9)',  # light strip look\n",
    "            showarrow = False\n",
    "        )\n",
    "\n",
    "    fig.for_each_annotation(pretty)\n",
    "    fig.update_yaxes(title_text = None)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_df['prompt_ix'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    plot_df\\\n",
    "    .sort_values('sample_ix')\\\n",
    "    .assign(probs_smoothed = lambda df: df.groupby(['prompt_ix', 'role_space'])['prob'].rolling(window_size, min_periods = 1).mean().reset_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b12751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get averages across roles\n",
    "\"\"\"\n",
    "plot_df =redteam_seqs_df.pipe(lambda df: df[df['output_class'].isin(['REFUSAL', 'HARMFUL_RESPONSE'])]).groupby(['redteam_prompt_type', 'output_class']).agg(\n",
    "    count = ('redteam_seq_ix', 'count')\n",
    ").reset_index()\\\n",
    "    .assign(redteam_prompt_type = lambda df: np.where(df['redteam_prompt_type'] == 'synthetic_policy', 'CoT Forgery', df['redteam_prompt_type']))\\\n",
    "    .assign(redteam_prompt_type = lambda df: np.where(df['redteam_prompt_type'] == 'destyled_policy', 'Destyled CoT Forgery', df['redteam_prompt_type']))\\\n",
    "    .assign(redteam_prompt_type = lambda df: np.where(df['redteam_prompt_type'] == 'base', 'Base', df['redteam_prompt_type']))\n",
    "\n",
    "\n",
    "\n",
    "# Convert counts to percentages within each prompt type\n",
    "df_percent = plot_df.copy()\n",
    "df_percent['percent'] = df_percent.groupby('redteam_prompt_type')['count'].transform(lambda x: 100 * x / x.sum())\n",
    "\n",
    "# Plot percentages instead of counts\n",
    "fig = px.bar(\n",
    "    df_percent,\n",
    "    x='redteam_prompt_type',\n",
    "    y='percent',\n",
    "    width = 600,\n",
    "    color='output_class',\n",
    "    barmode='group',\n",
    "    labels={\n",
    "        'redteam_prompt_type': 'Prompt Type',\n",
    "        'percent': 'Percentage (%)',\n",
    "        'output_class': 'Output Class'\n",
    "    },\n",
    "    title='Percentage Distribution of Output Classes by Redteam Prompt Type'\n",
    ")\n",
    "\n",
    "fig.update_layout(template='plotly_white', yaxis=dict(ticksuffix='%'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d961ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Project redteam activations into roles - start with just one sequence\n",
    "\"\"\"\n",
    "# Test sequences - get all variants\n",
    "test_variants = redteam_seqs_df#.pipe(lambda df: df[df['harm_index'] == redteam_seqs_df['harm_index'].tolist()[19]])\n",
    "\n",
    "test_variant_results = []\n",
    "plot_dfs = []\n",
    "for row in tqdm(test_variants.to_records('dict')[0:10]):\n",
    "    seq_samples = redteam_sample_df.pipe(lambda df: df[df['seq_id'] == row['redteam_seq_ix']]).pipe(lambda df: df[df['role'].notna()]).reset_index(drop = True)\n",
    "\n",
    "    seq_hs_cp = cupy.asarray(redteam_all_pre_mlp_hs[test_layer][seq_samples['sample_ix'].tolist(), :])\n",
    "\n",
    "    seq_probs = lr_model.predict_proba(seq_hs_cp).round(6)\n",
    "\n",
    "    # Merge seq probs with inputs\n",
    "    plot_df =\\\n",
    "        pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(cupy.asnumpy(seq_probs), columns = ['user', 'assistant', 'cot', 'system']).clip(1e-6),\n",
    "                seq_samples[['token_in_seq_ix', 'token', 'role']]\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\\\n",
    "        .assign(\n",
    "            variant = row['redteam_prompt_type'],\n",
    "            output_class = row['output_class']\n",
    "        )\n",
    "    \n",
    "    plot_dfs.append(plot_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(plot_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.concat(plot_dfs)\\\n",
    "    .pipe(lambda df: df[df['token_in_seq_ix'] <= 1_000])\\\n",
    "    .groupby(['token_in_seq_ix', 'role', 'variant'], as_index = False).agg(\n",
    "        avg_cotness = ('cot', 'mean')\n",
    "    )\\\n",
    "    .groupby(['variant', 'role'], as_index = False)\\\n",
    "    .agg(\n",
    "        avg_cotness = ('avg_cotness', 'mean')\n",
    "    )\n",
    "\n",
    "# Pivot to Variant x Role matrix and convert to %\n",
    "variant_map = {\n",
    "    \"synthetic_policy\": \"CoT forgery\",\n",
    "    \"destyled_policy\": \"Destyled CoT forgery\",\n",
    "    \"base\": \"Base\",\n",
    "}\n",
    "variant_order = [\"Base\", \"CoT forgery\", \"Destyled CoT forgery\"]\n",
    "role_order = [\"system\", \"user\", \"cot\", \"assistant\"]\n",
    "\n",
    "df = plot_df.copy()\n",
    "df[\"variant_label\"] = df[\"variant\"].map(variant_map).fillna(df[\"variant\"])\n",
    "\n",
    "# Pivot to Variant x Role and convert to %\n",
    "tbl = (df.pivot_table(index=\"variant_label\", columns=\"role\",\n",
    "                      values=\"avg_cotness\", aggfunc=\"mean\")\n",
    "         .reindex(variant_order)\n",
    "         .reindex(columns=role_order))\n",
    "tbl_pct = (tbl * 100).round(1)\n",
    "\n",
    "# --- Lighter color scale for cells ---\n",
    "scale = px.colors.sequential.Blues[:6]  # use lighter half\n",
    "min_v, max_v = np.nanmin(tbl_pct.values), np.nanmax(tbl_pct.values)\n",
    "\n",
    "def val_to_color(v):\n",
    "    if pd.isna(v) or max_v == min_v:\n",
    "        return \"#ffffff\"\n",
    "    t = (v - min_v) / (max_v - min_v)\n",
    "    idx = int(round(t * (len(scale) - 1)))\n",
    "    return scale[idx]\n",
    "\n",
    "# Build column-wise fill colors (first column is the row header)\n",
    "fill_colors = []\n",
    "fill_colors.append([\"#ffffff\"] * len(tbl_pct))  # first column (Variant)\n",
    "for col in tbl_pct.columns:\n",
    "    fill_colors.append([val_to_color(v) for v in tbl_pct[col].tolist()])\n",
    "\n",
    "# Values for display\n",
    "cell_values = [tbl_pct.index.tolist()] + [\n",
    "    [f\"{v:.1f}%\" if pd.notna(v) else \"\" for v in tbl_pct[col]] for col in tbl_pct.columns\n",
    "]\n",
    "\n",
    "# --- Plotly Table (narrower width, lighter header bg) ---\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    columnwidth=[170] + [110] * len(tbl_pct.columns),  # make table less wide\n",
    "    header=dict(\n",
    "        values=[\"Variant\"] + [c.title() for c in tbl_pct.columns],\n",
    "        fill_color=\"#eef3fb\",         # lighter header background\n",
    "        font=dict(color=\"#222\", size=12),\n",
    "        align=\"left\",\n",
    "        height=30\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=cell_values,\n",
    "        fill_color=fill_colors,\n",
    "        align=\"left\",\n",
    "        height=26,\n",
    "        font=dict(size=11, color=\"#222\")\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Avg CoTness by Variant × Role\",\n",
    "    width=680,  # narrower figure\n",
    "    margin=dict(l=10, r=10, t=50, b=10)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2652940",
   "metadata": {},
   "source": [
    "## Role spaces (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eafca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split by roles\n",
    "\"\"\"\n",
    "c4_role_hs = {}\n",
    "c4_role_sample_dfs = {}\n",
    "c4_role_topk_dfs = {}\n",
    "\n",
    "for role in ['system', 'user', 'cot', 'assistant']:\n",
    "    c4_role_sample_dfs[role] = c4_sample_df.pipe(lambda df: df[df['role'] == role]).pipe(lambda df: df[df['is_role_wrapper'] == 0])\n",
    "    c4_role_topk_dfs[role] = c4_topk_df[c4_topk_df['sample_ix'].isin(c4_role_sample_dfs[role]['sample_ix'].tolist())]\n",
    "\n",
    "    # Get corresponding hidden states + cast to f32 for linalg needed for lda\n",
    "    c4_role_hs[role] = {l: c4_all_pre_mlp_hs[l][c4_role_sample_dfs[role]['sample_ix'].tolist(), :].float() for l in c4_all_pre_mlp_hs.keys()}\n",
    "    print(c4_role_hs[role][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_role_plane(states: dict[str, list[torch.Tensor]], target_layer: int = 12, ridge_alpha: float = 1e-3):\n",
    "    \"\"\"\n",
    "    Params\n",
    "        @states: dict with keys {'system', 'user', 'cot', 'assistant'}. Each value is a list over layers; states[r][L] has shape (T, D) with matched token ordering across roles.\n",
    "        @target_layer: layer to use for LDA.\n",
    "        @ridge_alpha: small diagonal added to the pooled within-class covariance.\n",
    "    \"\"\"\n",
    "    roles = ['system', 'user', 'cot', 'assistant']\n",
    "    for r in roles:\n",
    "        assert r in states, f\"Missing role: {r}\"\n",
    "\n",
    "    X = {r: states[r][target_layer].to(dtype=torch.float32) for r in roles}  # (T, D)\n",
    "    T, D = X['assistant'].shape\n",
    "    device = X['assistant'].device\n",
    "\n",
    "    # 1) Content-centering per token across roles (removes shared content identity)\n",
    "    M_token = torch.stack([X[r] for r in roles], dim=0).mean(dim=0)            # (T, D)\n",
    "    Xc = {r: X[r] - M_token for r in roles}\n",
    "\n",
    "    # 2) Pooled within-class covariance (on centered data)\n",
    "    mu = {r: Xc[r].mean(dim=0) for r in roles}                                  # (D,)\n",
    "    residuals = torch.cat([Xc[r] - mu[r] for r in roles], dim=0)                # (4T, D)\n",
    "    cov = (residuals.T @ residuals) / max(1, residuals.shape[0] - len(roles))   # (D, D)\n",
    "    lam = ridge_alpha * (cov.trace() / D)\n",
    "    cov = cov + lam * torch.eye(D, device=device, dtype=cov.dtype)\n",
    "\n",
    "    # 3) Whitening transform: W such that W @ cov @ W^T = I\n",
    "    evals, evecs = torch.linalg.eigh(cov)                                       # ascending\n",
    "    inv_sqrt = torch.diag(torch.rsqrt(evals.clamp_min(1e-12)))\n",
    "    W = (evecs @ inv_sqrt @ evecs.T).to(torch.float32)                           # (D, D)\n",
    "\n",
    "    # 4) Whitened class centroids\n",
    "    mu_w = {r: (Xc[r] @ W.T).mean(dim=0) for r in roles}                        # (D,)\n",
    "\n",
    "    # 5) Define Role Plane axes in whitened space\n",
    "    # Speaker: (assistant-like) vs (non-assistant)\n",
    "    speaker = (mu_w['assistant'] + mu_w['cot'] - mu_w['user'] - mu_w['system']) / 2.0\n",
    "    speaker = speaker / (speaker.norm() + 1e-12)\n",
    "\n",
    "    # CoT: assistant-cot vs assistant-out, orthogonalized to speaker\n",
    "    cot = mu_w['cot'] - mu_w['assistant']\n",
    "    cot = cot - (cot @ speaker) * speaker\n",
    "    cot = cot / (cot.norm() + 1e-12)\n",
    "\n",
    "    P_role = torch.stack([speaker, cot], dim=0)                                  # (2, D)\n",
    "\n",
    "    # 6) Fix axis signs for interpretability (assistant has +speaker; cot>assistant on +cot)\n",
    "    asst_coords = mu_w['assistant'] @ P_role.T\n",
    "    cot_coords  = mu_w['cot']       @ P_role.T\n",
    "    if asst_coords[0] < 0:  # speaker axis\n",
    "        P_role[0] = -P_role[0]\n",
    "    if (cot_coords - asst_coords)[1] < 0:  # cot axis\n",
    "        P_role[1] = -P_role[1]\n",
    "\n",
    "    # 7) Axis standardization stats (z-scores) computed on training tokens\n",
    "    Z_all = torch.cat([(Xc[r] @ W.T) @ P_role.T for r in roles], dim=0)          # (4T, 2)\n",
    "    axis_mean = Z_all.mean(dim=0)\n",
    "    axis_std  = Z_all.std(dim=0).clamp_min(1e-6)\n",
    "\n",
    "    # Global mean as a fallback for unpaired inference (when M_token is unavailable)\n",
    "    M_global = M_token.mean(dim=0)                                              # (D,)\n",
    "\n",
    "    return {\n",
    "        'roles': roles,\n",
    "        'W': W,                   # (D, D) whitening\n",
    "        'P_role': P_role,         # (2, D) rows: [speaker_axis, cot_axis]\n",
    "        'mu_w': mu_w,             # role centroids in whitened space\n",
    "        'axis_mean': axis_mean,   # (2,)\n",
    "        'axis_std': axis_std,     # (2,)\n",
    "        'M_global': M_global,     # (D,)\n",
    "        'dtype': torch.float32,\n",
    "        'device': device,\n",
    "    }\n",
    "    \n",
    "    \n",
    "def project_role_plane(x: torch.Tensor, rp: dict, content_mean: torch.Tensor | None = None):\n",
    "    \"\"\"\n",
    "    Project hidden states x (..., D) into the Role Plane.\n",
    "\n",
    "    content_mean: if you have the *paired* per-token mean across roles (M_token[i]), pass it here for precise content-centering. Otherwise we use rp['M_global'].\n",
    "\n",
    "    Returns:\n",
    "      coords: (..., 2) raw coordinates along (speaker, cot)\n",
    "      zcoords: (..., 2) standardized z-scores along (speaker, cot)\n",
    "    \"\"\"\n",
    "    W, P = rp['W'], rp['P_role']\n",
    "    base = content_mean if content_mean is not None else rp['M_global']\n",
    "    z = (x - base) @ W.T                     # whitened\n",
    "    coords = z @ P.T                         # (..., 2)\n",
    "    zcoords = (coords - rp['axis_mean']) / rp['axis_std']\n",
    "    return coords, zcoords\n",
    "\n",
    "\n",
    "lda = fit_role_plane(c4_role_hs, target_layer = test_layer, ridge_alpha = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variants = redteam_seqs_df.pipe(lambda df: df[df['harm_index'] == redteam_seqs_df['harm_index'].tolist()[0]])\n",
    "\n",
    "test_variant_results = []\n",
    "for row in test_variants.to_records('dict'):\n",
    "    seq_samples = redteam_sample_df.pipe(lambda df: df[df['seq_id'] == row['redteam_seq_ix']]).pipe(lambda df: df[df['role'].notna()]).reset_index(drop = True)\n",
    "\n",
    "    seq_hs_pt = torch.Tensor(redteam_all_pre_mlp_hs[test_layer][seq_samples['sample_ix'].tolist(), :]) # (N, D)\n",
    "    print(seq_hs_pt.shape)\n",
    "    \n",
    "    coords, zcoords = project_role_plane(seq_hs_pt, lda)\n",
    "\n",
    "    # Merge seq probs with inputs\n",
    "    plot_df =\\\n",
    "        pd.concat(\n",
    "            [\n",
    "                pd.DataFrame({\n",
    "                    'speaker_axis': coords[:, 0],\n",
    "                    'channel_axis': coords[:, 1]\n",
    "                }).clip(1e-6),\n",
    "                seq_samples[['token_in_seq_ix', 'token', 'role']]\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "    test_variant_results.append({\n",
    "        'variant': row['redteam_prompt_type'],\n",
    "        'output_class': row['output_class'],\n",
    "        'plot_df': plot_df\n",
    "    })\n",
    "\n",
    "test_variant_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prep_df(df: pd.DataFrame, smoothing: int = 25) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # Expected columns: token_in_seq_ix, token, speaker_axis, channel_axis, role\n",
    "    df = df.sort_values(\"token_in_seq_ix\").reset_index(drop=True)\n",
    "\n",
    "    # Rolling means (centered) for smoother overlay\n",
    "    win = max(1, int(smoothing))\n",
    "    minp = max(1, win // 2)\n",
    "    df[\"speaker_smooth\"] = (\n",
    "        df[\"speaker_axis\"].rolling(win, min_periods=minp, center=True).mean()\n",
    "    )\n",
    "    df[\"channel_smooth\"] = (\n",
    "        df[\"channel_axis\"].rolling(win, min_periods=minp, center=True).mean()\n",
    "    )\n",
    "\n",
    "    # Role boundaries (indices where the role changes)\n",
    "    role_change_mask = df[\"role\"].ne(df[\"role\"].shift(1))\n",
    "    df[\"_role_change\"] = role_change_mask\n",
    "    df[\"_role_start_ix\"] = df.loc[role_change_mask, \"token_in_seq_ix\"]\n",
    "    return df\n",
    "\n",
    "def _add_role_boundaries(fig: go.Figure, df: pd.DataFrame) -> None:\n",
    "    # Draw a vertical line at each role change (skip the very first token)\n",
    "    change_ix = df.loc[df[\"_role_change\"], \"token_in_seq_ix\"].tolist()\n",
    "    for x in change_ix[1:]:\n",
    "        fig.add_vline(x=x, line_dash=\"dash\", opacity=0.25)\n",
    "\n",
    "def _auto_symmetric_range(series_list):\n",
    "    # Symmetric y-range around 0 so the zero-line is centered\n",
    "    vals = np.concatenate([np.asarray(s.dropna().values) for s in series_list if s is not None])\n",
    "    if vals.size == 0:\n",
    "        return None\n",
    "    m = float(np.nanmax(np.abs(vals)))\n",
    "    if m == 0 or np.isnan(m):\n",
    "        return None\n",
    "    pad = 0.05 * m\n",
    "    return [-m - pad, m + pad]\n",
    "\n",
    "def make_role_plane_figures(\n",
    "    df: pd.DataFrame,\n",
    "    smoothing: int = 25,\n",
    "    show_rangeslider: bool = True,\n",
    "    scatter_opacity: float = 0.65,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns three Plotly figures:\n",
    "      (1) fig_speaker_timeline : token index vs speaker_axis (+ rolling mean)\n",
    "      (2) fig_channel_timeline : token index vs channel_axis (+ rolling mean)\n",
    "      (3) fig_role_plane       : 2D scatter of speaker_axis vs channel_axis\n",
    "    \"\"\"\n",
    "    df = _prep_df(df, smoothing)\n",
    "\n",
    "    # ---- 1) Speaker axis over time ----\n",
    "    fig_speaker = px.scatter(\n",
    "        df,\n",
    "        x=\"token_in_seq_ix\",\n",
    "        y=\"speaker_axis\",\n",
    "        color=\"role\",\n",
    "        hover_data={\n",
    "            \"token_in_seq_ix\": True,\n",
    "            \"token\": True,\n",
    "            \"speaker_axis\": \":.3f\",\n",
    "            \"channel_axis\": \":.3f\",\n",
    "            \"role\": True,\n",
    "        },\n",
    "        opacity=scatter_opacity,\n",
    "        category_orders={\"role\": [\"system\", \"user\", \"cot\", \"assistant\"]},\n",
    "        title=\"Speaker axis over sequence (assistant‑ish ↔ non‑assistant)\",\n",
    "    )\n",
    "    fig_speaker.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"token_in_seq_ix\"],\n",
    "            y=df[\"speaker_smooth\"],\n",
    "            mode=\"lines\",\n",
    "            name=f\"rolling mean ({smoothing})\",\n",
    "        )\n",
    "    )\n",
    "    fig_speaker.add_hline(y=0, line_dash=\"dot\")\n",
    "    _add_role_boundaries(fig_speaker, df)\n",
    "    yr = _auto_symmetric_range([df[\"speaker_axis\"], df[\"speaker_smooth\"]])\n",
    "    if yr is not None:\n",
    "        fig_speaker.update_yaxes(range=yr)\n",
    "    fig_speaker.update_layout(\n",
    "        xaxis_title=\"Token index in sequence\",\n",
    "        yaxis_title=\"Speaker axis\",\n",
    "        hovermode=\"x unified\",\n",
    "        legend_title_text=\"Role\",\n",
    "    )\n",
    "    if show_rangeslider:\n",
    "        fig_speaker.update_layout(xaxis_rangeslider_visible=True)\n",
    "\n",
    "    # ---- 2) Channel/CoT axis over time ----\n",
    "    fig_channel = px.scatter(\n",
    "        df,\n",
    "        x=\"token_in_seq_ix\",\n",
    "        y=\"channel_axis\",\n",
    "        color=\"role\",\n",
    "        hover_data={\n",
    "            \"token_in_seq_ix\": True,\n",
    "            \"token\": True,\n",
    "            \"speaker_axis\": \":.3f\",\n",
    "            \"channel_axis\": \":.3f\",\n",
    "            \"role\": True,\n",
    "        },\n",
    "        opacity=scatter_opacity,\n",
    "        category_orders={\"role\": [\"system\", \"user\", \"cot\", \"assistant\"]},\n",
    "        title=\"CoT / channel axis over sequence (assistant‑CoT ↔ assistant‑final)\",\n",
    "    )\n",
    "    fig_channel.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"token_in_seq_ix\"],\n",
    "            y=df[\"channel_smooth\"],\n",
    "            mode=\"lines\",\n",
    "            name=f\"rolling mean ({smoothing})\",\n",
    "        )\n",
    "    )\n",
    "    fig_channel.add_hline(y=0, line_dash=\"dot\")\n",
    "    _add_role_boundaries(fig_channel, df)\n",
    "    yr = _auto_symmetric_range([df[\"channel_axis\"], df[\"channel_smooth\"]])\n",
    "    if yr is not None:\n",
    "        fig_channel.update_yaxes(range=yr)\n",
    "    fig_channel.update_layout(\n",
    "        xaxis_title=\"Token index in sequence\",\n",
    "        yaxis_title=\"CoT / channel axis\",\n",
    "        hovermode=\"x unified\",\n",
    "        legend_title_text=\"Role\",\n",
    "    )\n",
    "    if show_rangeslider:\n",
    "        fig_channel.update_layout(xaxis_rangeslider_visible=True)\n",
    "\n",
    "    # ---- 3) 2‑D Role Plane scatter ----\n",
    "    fig_plane = px.scatter(\n",
    "        df,\n",
    "        x=\"speaker_axis\",\n",
    "        y=\"channel_axis\",\n",
    "        color=\"role\",\n",
    "        hover_data={\n",
    "            \"token_in_seq_ix\": True,\n",
    "            \"token\": True,\n",
    "            \"speaker_axis\": \":.3f\",\n",
    "            \"channel_axis\": \":.3f\",\n",
    "            \"role\": True,\n",
    "        },\n",
    "        opacity=scatter_opacity,\n",
    "        category_orders={\"role\": [\"system\", \"user\", \"cot\", \"assistant\"]},\n",
    "        title=\"Role Plane (x: speaker axis, y: CoT/channel axis)\",\n",
    "    )\n",
    "    fig_plane.add_vline(x=0, line_dash=\"dot\")\n",
    "    fig_plane.add_hline(y=0, line_dash=\"dot\")\n",
    "    fig_plane.update_layout(\n",
    "        xaxis_title=\"Speaker axis\",\n",
    "        yaxis_title=\"CoT / channel axis\",\n",
    "        legend_title_text=\"Role\",\n",
    "    )\n",
    "\n",
    "    return fig_speaker, fig_channel, fig_plane\n",
    "\n",
    "# --- Example usage (uncomment to run) ---\n",
    "fig_speaker, fig_channel, fig_plane = make_role_plane_figures(test_variant_results[0]['plot_df'], smoothing=25)\n",
    "fig_speaker.show()\n",
    "fig_channel.show()\n",
    "fig_plane.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_role_prob_minimal(\n",
    "    input_df: pd.DataFrame,\n",
    "    *,\n",
    "    title: str = '',\n",
    "    value_col: str = \"cot\", # one of: 'cot','assistant','user','system'\n",
    "    rolling_window: int = 35, # used for line mode only\n",
    "    use_points: bool = False, # True -> markers (raw), False -> line (smoothed)\n",
    "    export_path: str = None # e.g. \"figure.svg\" (requires kaleido)\n",
    "):\n",
    "    \"\"\"\n",
    "    Minimal, publication-ready plot of a single role probability across tokens.\n",
    "\n",
    "    - Line mode (default): rolling-smoothed curve (clean trend).\n",
    "    - Points mode: raw per-token probabilities as markers (no smoothing).\n",
    "\n",
    "    Expects columns: role, token_ix, assistant, cot, user, system.\n",
    "    \"\"\"\n",
    "    allowed = {'system', 'user', 'cot', 'assistant'}\n",
    "    if value_col not in allowed:\n",
    "        raise ValueError(f\"value_col must be one of {allowed}, got {value_col!r}\")\n",
    "\n",
    "    line_color = {\n",
    "        \"cot\": \"#0072B2\",  # blue\n",
    "        \"assistant\": \"#D55E00\",  # vermillion\n",
    "        \"user\": \"#009E73\",  # bluish green\n",
    "        \"system\": \"#CC79A7\",  # reddish purple\n",
    "    }[value_col]\n",
    "\n",
    "    role_bg = {\n",
    "        \"user\": \"rgba(0,158,115,0.28)\",\n",
    "        \"assistant\": \"rgba(213,94,0,0.24)\",\n",
    "        \"cot\": \"rgba(0,114,178,0.24)\",\n",
    "        \"system\": \"rgba(204,121,167,0.24)\",\n",
    "    }\n",
    "    role_label = {\"user\": \"USER\", \"assistant\": \"ASSISTANT\", \"cot\": \"REASONING\", \"system\": \"SYSTEM\",}\n",
    "    y_label = {\n",
    "        \"cot\": \"less ←       CoTness       ⟶ more\",\n",
    "        \"assistant\": \"Assistantness\",\n",
    "        \"user\": \"Userness \",\n",
    "        \"system\": \"Systemness   P(role = System)\",\n",
    "    }[value_col]\n",
    "\n",
    "    # Data\n",
    "    df = input_df.copy().sort_values(\"token_in_seq_ix\", kind=\"mergesort\")\n",
    "    x = df[\"token_in_seq_ix\"].to_numpy()\n",
    "    y_raw = df[value_col].to_numpy()\n",
    "    roles = df[\"role\"].to_numpy()\n",
    "\n",
    "    # Rolling smoothing for line mode\n",
    "    if use_points:\n",
    "        y_plot = y_raw  # Points show raw values\n",
    "    else:\n",
    "        y_plot = pd.Series(y_raw).rolling(rolling_window, center=True, min_periods=1).mean().to_numpy()\n",
    "\n",
    "    # Contiguous role regions (actual roles)\n",
    "    regions = []\n",
    "    start = 0\n",
    "    for i in range(1, len(df)):\n",
    "        if roles[i] != roles[i-1]:\n",
    "            regions.append((roles[start], int(x[start]), int(x[i-1])))\n",
    "            start = i\n",
    "    regions.append((roles[start], int(x[start]), int(x[-1])))\n",
    "\n",
    "    # Figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Background bands + labels\n",
    "    for role, x0, x1 in regions:\n",
    "        fig.add_vrect(\n",
    "            x0=x0 - 0.5, x1=x1 + 0.5,\n",
    "            fillcolor=role_bg.get(role, \"rgba(200,200,200,0.22)\"),\n",
    "            line_width=0, layer=\"below\"\n",
    "        )\n",
    "        if x1 - x0 >= 10:\n",
    "            fig.add_annotation(\n",
    "                x=(x0 + x1)/2, y=1.045, xref=\"x\", yref=\"paper\",\n",
    "                text=role_label.get(role, role),\n",
    "                showarrow=False,\n",
    "                font=dict(size=12, color=\"rgba(0,0,0,0.70)\", family=\"Helvetica, Arial, sans-serif\")\n",
    "            )\n",
    "\n",
    "    if use_points:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y_plot, mode=\"markers\",\n",
    "            marker=dict(color=line_color, size=5, opacity=0.85, line=dict(width=0)),\n",
    "            hoverinfo=\"skip\", showlegend=False\n",
    "        ))\n",
    "    else:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y_plot, mode=\"lines\",\n",
    "            line=dict(color=line_color, width=3.6),\n",
    "            hoverinfo=\"skip\", showlegend=False\n",
    "        ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        template=\"simple_white\",\n",
    "        width=1100, height=420,\n",
    "        margin=dict(l=70, r=30, t=64, b=54),\n",
    "        title=dict(text=title, x=0.01, y=0.98, xanchor=\"left\", font=dict(size=20, family=\"Helvetica, Arial, sans-serif\")),\n",
    "        font=dict(size=14, family=\"Helvetica, Arial, sans-serif\"),\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        # type = 'log',\n",
    "        # range=[0, 20],\n",
    "        # dtick=0.25,\n",
    "        title_text=y_label, gridcolor=\"rgba(0,0,0,0.06)\")\n",
    "    fig.update_xaxes(title_text=\"Token index\", showgrid=False, zeroline=False)\n",
    "\n",
    "    if export_path:\n",
    "        fig.write_image(export_path, scale=2)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "figs = []\n",
    "for tests_variant in test_variant_results:\n",
    "    fig = plot_role_prob_minimal(tests_variant['plot_df'], title = tests_variant['variant'], value_col = 'cot', use_points = True, export_path = None)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
