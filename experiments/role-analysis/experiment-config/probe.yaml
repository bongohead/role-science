# This file contains training probe training + eval setting for each model.

gptoss-20b:
  n_sample_size: 400
  seq_len: 1280
  nested_reasoning: false
  train_prefixes:
    - ""
    # - "<|startoftext|>"
    # - "<|startoftext|><|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-31\n\nReasoning: medium\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|>"
  train_params:
    C: 5.0e-3
    add_scaling: false
  test_prefix: |-
    <|startoftext|><|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
    Knowledge cutoff: 2024-06
    Current date: 2025-12-31

    Reasoning: medium

    # Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|>
  test_seperators:
    # For untagged conversations, # lbs between roles (set it to match the true instruct format, - use 1 space if there are no lbs to prevent role mergnig)
    # gpt-oss_*: there are no newlines between roles - add space to prevent cross-role toks
    untagged_role_sep: " "
    # For untagged conversations, # lbs between test_prefix and user text (set it to match the true instruct format)
    # gpt-oss_*: there are no newlines between the test_prefix (system prompt) and the user text - add space to prevent cross-role toks
    untagged_start_sep: " "
    # For tagged conversations, # lbs between the test prefix and user role (including XML tags belonging to the role)
    # gpt-oss_*: there are no newlines between the test_prefix (system prompt) and the first user role tags - add space to prevent cross-role toks
    tagged_start_sep: " "
    # Note there is no tagged_role_sep since the render_single_* outputs should already be concatenatable without extra lbs

gptoss-120b:
  n_sample_size: 250
  seq_len: 1280
  nested_reasoning: false
  train_prefixes:
    - ""
    # - "<|startoftext|>"
    # - "<|startoftext|><|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-31\n\nReasoning: medium\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|>"
  train_params:
    C: 5.0e-3
    add_scaling: true
  test_prefix: |-
    <|startoftext|><|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
    Knowledge cutoff: 2024-06
    Current date: 2025-12-31

    Reasoning: medium

    # Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|>
  test_seperators:
    untagged_role_sep: " "
    untagged_start_sep: " "
    tagged_start_sep: " "

nemotron-3-nano:
  n_sample_size: 250
  seq_len: 1024
  nested_reasoning: true
  train_prefixes:
    - ""
    # - "<s>"
    # - "<s><|im_start|>system\n<|im_end|>\n"
  train_params:
    C: 1.0e+1
    add_scaling: false
  test_prefix: |-
    <s><|im_start|>system
    <|im_end|>
  test_seperators:
    untagged_role_sep: "\n\n"
    untagged_start_sep: "\n\n"
    tagged_start_sep: "\n"

glm-4.5-air:
  n_sample_size: 250
  seq_len: 1024
  nested_reasoning: true
  train_prefixes:
    - ""
    # - "<s>"
    # - "<s><|im_start|>system\n<|im_end|>\n"
  train_params:
    C: 1.0e-3
    add_scaling: false
  test_prefix: |-
    <s><|im_start|>system
    <|im_end|>
  test_seperators:
    untagged_role_sep: "\n\n"
    untagged_start_sep: "\n\n"
    tagged_start_sep: "\n"

glm-4.6v-flash:
  n_sample_size: 250
  seq_len: 1024
  nested_reasoning: true
  train_prefixes:
    - ""
  train_params:
    C: 5.0e-4
    add_scaling: false
  test_prefix: |-
    [gMASK]<sop><|system|>
    # Tools
    
    You may call one or more functions to assist with the user query.
    
    You are provided with function signatures within <tools></tools> XML tags:
    <tools>
    </tools>

    For each function call, output the function name and arguments within the following XML format:
    <tool_call>{function-name}
    <arg_key>{arg-key-1}</arg_key>
    <arg_value>{arg-value-1}</arg_value>
    <arg_key>{arg-key-2}</arg_key>
    <arg_value>{arg-value-2}</arg_value>
    ...
    </tool_call>
  test_seperators:
    untagged_role_sep: "\n\n"
    untagged_start_sep: "\n\n"
    tagged_start_sep: "\n"

qwen3-30b-a3b: 
  n_sample_size: 250
  seq_len: 1024
  nested_reasoning: true
  train_prefixes:
    - ""
  train_params:
    C: 1.0e-1
    add_scaling: false
  test_prefix: |-
    <|im_start|>system
    <|im_end|>
  test_seperators:
    untagged_role_sep: "\n\n"
    untagged_start_sep: "\n\n"
    tagged_start_sep: "\n"

jamba-reasoning: 
  n_sample_size: 250
  seq_len: 1024
  nested_reasoning: true
  train_prefixes:
    - ""
  train_params:
    C: 1.0
    add_scaling: false
  test_prefix: |-
    <|startoftext|>
  test_seperators:
    untagged_role_sep: "\n\n"
    untagged_start_sep: "\n"
    tagged_start_sep: ""

olmo3-7b-think: 
  n_sample_size: 250
  seq_len: 1024
  nested_reasoning: true
  train_prefixes:
    - ""
  train_params:
    C: 1.0e-1
    add_scaling: false
  test_prefix: |-
    <|endoftext|><|im_start|>system
    You are a helpful AI assistant.<|im_end|>
  test_seperators:
    untagged_role_sep: "\n\n"
    untagged_start_sep: "\n\n"
    tagged_start_sep: "\n"

apriel-1.6-15b-thinker: 
  n_sample_size: 250
  seq_len: 1024
  nested_reasoning: true
  train_prefixes:
    - ""
    # - "<s>"
    # - "<|begin_system|>\nYou are a thoughtful, systematic AI assistant from ServiceNow Language Models (SLAM) lab. Analyze each question carefully, present your reasoning step-by-step, then provide the final response after the marker [BEGIN FINAL RESPONSE].\n"
  train_params:
    C: 1.0e-2
    add_scaling: false
  test_prefix: |-
    <s><|begin_system|>
    You are a thoughtful, systematic AI assistant from ServiceNow Language Models (SLAM) lab. Analyze each question carefully, present your reasoning step-by-step, then provide the final response after the marker [BEGIN FINAL RESPONSE].
  test_seperators:
    untagged_role_sep: "\n\n"
    untagged_start_sep: "\n\n"
    tagged_start_sep: "\n"